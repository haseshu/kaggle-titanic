{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# いろんなモデルを作ってアンサンブルする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import math\n",
    "import scipy as sp\n",
    "sns.set()\n",
    "\n",
    "\n",
    "import requests,zipfile\n",
    "import io\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 3\n",
    "\n",
    "np.random.seed(0)\n",
    "import scipy.stats as st\n",
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "#features = ['Pclass', 'Sex', 'Age', 'FamilySize', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "features = ['Age*Pclass', 'Sex',  'FamilySize', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#バッチサイズ　1回に取り出すデータ数\n",
    "#エポック数　トレーニングのセット数\n",
    "#過剰適合ならエポック数を減らし、未収束ならエポック数を増やす\n",
    "batch_size=128\n",
    "num_class =10\n",
    "epochs =20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#モデル評価用\n",
    "\n",
    "model_score=pd.DataFrame([],columns=['model', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここから先cross varidationの練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data=pd.read_csv('train.csv',sep=',')\n",
    "cv_test_data=pd.read_csv('test.csv',sep=',')\n",
    "cv_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\seaborn\\axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\seaborn\\axisgrid.py:715: UserWarning: Using the pointplot function without specifying `order` is likely to produce an incorrect plot.\n",
      "  warnings.warn(warning)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\seaborn\\axisgrid.py:720: UserWarning: Using the pointplot function without specifying `hue_order` is likely to produce an incorrect plot.\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1b708e91e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAHTCAYAAACpwOSlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkzP+H6XL7Y8A+5dzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 326.29x475.2 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#性別と乗った港、クラスによって生存率がかわるか。\n",
    "\n",
    "# grid = sns.FacetGrid(train_df, col='Embarked')\n",
    "grid = sns.FacetGrid(cv_train_data, row='Embarked', size=2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\seaborn\\axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\seaborn\\axisgrid.py:715: UserWarning: Using the barplot function without specifying `order` is likely to produce an incorrect plot.\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1b708e91e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAHTCAYAAABROqDmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 515.68x475.2 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(cv_train_data, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_mean=cv_train_data['Age'].mean()\n",
    "fare_mean=cv_train_data['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ageとfareについて、EmbarkedとPclassごとの平均と標準偏差をとって、それで定義することにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0 41.2625\n",
      "30.0 13.0\n",
      "25.0 7.925\n",
      "35.0 82.66454999999999\n",
      "28.0 22.0\n",
      "21.5 12.475\n"
     ]
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "guess_fares = np.zeros((2,3))\n",
    "cv_test_data=cv_test_data.replace('male',0)\n",
    "cv_test_data=cv_test_data.replace('female',1)\n",
    "cv_train_data=cv_train_data.replace('male',0)\n",
    "cv_train_data=cv_train_data.replace('female',1)\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        guess_df = cv_train_data[(cv_train_data['Sex'] == i) & (cv_train_data['Pclass'] == j+1)]['Age'].dropna()\n",
    "        guess_df_fare = cv_train_data[(cv_train_data['Sex'] == i) & (cv_train_data['Pclass'] == j+1)]['Fare'].dropna()\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "        age_guess = guess_df.median()\n",
    "        fare_guess=guess_df_fare.median()\n",
    "        print(age_guess,fare_guess)\n",
    "        guess_ages[i,j]=age_guess\n",
    "        guess_fares[i,j]=fare_guess\n",
    "            \n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        cv_train_data.loc[ (cv_train_data.Age.isnull()) & (cv_train_data.Sex == i) & (cv_train_data.Pclass == j+1),'Age'] = guess_ages[i,j]\n",
    "        cv_test_data.loc[ (cv_test_data.Age.isnull()) & (cv_test_data.Sex == i) & (cv_test_data.Pclass == j+1),'Age'] = guess_ages[i,j]\n",
    "        \n",
    "        cv_train_data.loc[ (cv_train_data.Fare.isnull()) & (cv_train_data.Sex == i) & (cv_train_data.Pclass == j+1),'Fare'] = guess_fares[i,j]\n",
    "        cv_test_data.loc[ (cv_test_data.Fare.isnull()) & (cv_test_data.Sex == i) & (cv_test_data.Pclass == j+1),'Fare'] = guess_fares[i,j]\n",
    "cv_train_data['Age'] = cv_train_data['Age'].astype(int)\n",
    "cv_test_data['Age'] = cv_test_data['Age'].astype(int)\n",
    "cv_train_data['Age'] = cv_train_data['Fare'].astype(int)\n",
    "cv_test_data['Age'] = cv_test_data['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#欠損を確認し、それをどうにかする\n",
    "#fillna('値'):欠損値を値に上書き\n",
    "#dropna():欠損値のある行を削除\n",
    "#print(pd.isnull(train_data_x.iloc[:,:]))\n",
    "\n",
    "#不要な説明変数を削除する\n",
    "#Name:客の名前なので削除\n",
    "\n",
    "if 'Name' in cv_train_data.columns:\n",
    "    cv_train_data=cv_train_data.drop(columns=['Name'])\n",
    "else:\n",
    "    print('Name is not found in cv_train_data')\n",
    "    \n",
    "\n",
    "\n",
    "#Ticket:チケット番号を削除\n",
    "if 'Ticket' in cv_train_data.columns:\n",
    "    cv_train_data=cv_train_data.drop(columns=['Ticket'])\n",
    "else:\n",
    "    print('Ticket is not found in cv_train_data')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#Sexをmale=0,female=1に変換する\n",
    "cv_train_data=cv_train_data.replace('male',0)\n",
    "cv_train_data=cv_train_data.replace('female',1)\n",
    "\n",
    "\n",
    "#Embarkedをダミー変数に変換する\n",
    "cv_train_data=pd.concat([cv_train_data, pd.get_dummies(cv_train_data['Embarked'], prefix='Embarked')], axis=1)\n",
    "if 'Embarked' in cv_train_data.columns:\n",
    "    cv_train_data=cv_train_data.drop(columns=['Embarked'])\n",
    "\n",
    "\n",
    "#Cabin 列が欠損が多いため削除する\n",
    "if 'Cabin' in cv_train_data.columns:\n",
    "    cv_train_data=cv_train_data.drop(columns=['Cabin'])\n",
    "else:\n",
    "    print('Cabin is not found in cv_train_data')\n",
    "    \n",
    "#SibSp \tParchを削除すると精度ダウンした。\n",
    "    \n",
    "#SibSp \tParchをまとめてFamilySizeにする\n",
    "\n",
    "if 'FamilySize' not in cv_train_data.columns:\n",
    "    cv_train_data['FamilySize']=cv_train_data['SibSp']+cv_train_data['Parch']\n",
    "\n",
    "if 'SibSp' in cv_train_data.columns:\n",
    "    cv_train_data=cv_train_data.drop(columns=['SibSp'])\n",
    "    cv_train_data=cv_train_data.drop(columns=['Parch'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#テストデータの処理\n",
    "#欠損を確認し、それをどうにかする\n",
    "#fillna('値'):欠損値を値に上書き\n",
    "#dropna():欠損値のある行を削除\n",
    "#print(pd.isnull(train_data_x.iloc[:,:]))\n",
    "\n",
    "#不要な説明変数を削除する\n",
    "#Name:客の名前なので削除\n",
    "\n",
    "if 'Name' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['Name'])\n",
    "else:\n",
    "    print('Name is not found in cv_test_data')\n",
    "    \n",
    "\n",
    "\n",
    "#Ticket:チケット番号を削除\n",
    "if 'Ticket' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['Ticket'])\n",
    "else:\n",
    "    print('Ticket is not found in cv_test_data')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#Sexをmale=0,female=1に変換する\n",
    "cv_test_data=cv_test_data.replace('male',0)\n",
    "cv_test_data=cv_test_data.replace('female',1)\n",
    "\n",
    "\n",
    "#Embarkedをダミー変数に変換する\n",
    "cv_test_data=pd.concat([cv_test_data, pd.get_dummies(cv_test_data['Embarked'], prefix='Embarked')], axis=1)\n",
    "if 'Embarked' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['Embarked'])\n",
    "\n",
    "\n",
    "#Cabin 列が欠損が多いため削除する\n",
    "if 'Cabin' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['Cabin'])\n",
    "else:\n",
    "    print('Cabin is not found in cv_test_data')\n",
    "    \n",
    "#SibSp \tParchを削除すると精度ダウンした。\n",
    "    \n",
    "#SibSp \tParchをまとめてFamilySizeにする\n",
    "\n",
    "if 'FamilySize' not in cv_test_data.columns:\n",
    "    cv_test_data['FamilySize']=cv_test_data['SibSp']+cv_test_data['Parch']\n",
    "\n",
    "if 'SibSp' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['SibSp'])\n",
    "    cv_test_data=cv_test_data.drop(columns=['Parch'])\n",
    "\n",
    "#とりあえず、Ageがカラの場合、平均値にする\n",
    "\n",
    "cv_test_data['Age'] = cv_test_data['Age'].fillna(age_mean)\n",
    "cv_test_data['Fare'] = cv_test_data['Fare'].fillna(fare_mean)\n",
    "\n",
    "#PassengerIdを落とす\n",
    "if 'PassengerId' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['PassengerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#とりあえず、Ageがカラの場合、平均値にする\n",
    "#上で乗船箇所とPclassと性別毎の平均値で作ったので不要。\n",
    "\n",
    "#cv_train_data['Age'] = cv_train_data['Age'].fillna(age_mean)\n",
    "#cv_train_data['Fare'] = cv_train_data['Fare'].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#とりあえず、Ageがカラの場合、平均値にする\n",
    "\n",
    "#cv_test_data['Age'] = cv_test_data['Age'].fillna(age_mean)\n",
    "#cv_test_data['Fare'] = cv_test_data['Fare'].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.040143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>0.257482</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.155660</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.550553</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182331</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.125722</td>\n",
       "      <td>0.200988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.257482</td>\n",
       "      <td>-0.550553</td>\n",
       "      <td>0.182331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.269165</td>\n",
       "      <td>-0.118319</td>\n",
       "      <td>-0.165803</td>\n",
       "      <td>0.217052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.166603</td>\n",
       "      <td>0.217138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.001205</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.269165</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.778359</td>\n",
       "      <td>-0.046215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.118319</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.496624</td>\n",
       "      <td>-0.058592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.155660</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>-0.125722</td>\n",
       "      <td>-0.165803</td>\n",
       "      <td>-0.166603</td>\n",
       "      <td>-0.778359</td>\n",
       "      <td>-0.496624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>0.217052</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.079977</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Sex       Age      Fare  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144 -0.042939  0.012668  0.012658   \n",
       "Survived       -0.005007  1.000000 -0.338481  0.543351  0.257482  0.257307   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.131900 -0.550553 -0.549500   \n",
       "Sex            -0.042939  0.543351 -0.131900  1.000000  0.182331  0.182333   \n",
       "Age             0.012668  0.257482 -0.550553  0.182331  1.000000  0.999979   \n",
       "Fare            0.012658  0.257307 -0.549500  0.182333  0.999979  1.000000   \n",
       "Embarked_C     -0.001205  0.168240 -0.243292  0.082853  0.269165  0.269335   \n",
       "Embarked_Q     -0.033606  0.003650  0.221009  0.074115 -0.118319 -0.117216   \n",
       "Embarked_S      0.022148 -0.155660  0.081720 -0.125722 -0.165803 -0.166603   \n",
       "FamilySize     -0.040143  0.016639  0.065997  0.200988  0.217052  0.217138   \n",
       "\n",
       "             Embarked_C  Embarked_Q  Embarked_S  FamilySize  \n",
       "PassengerId   -0.001205   -0.033606    0.022148   -0.040143  \n",
       "Survived       0.168240    0.003650   -0.155660    0.016639  \n",
       "Pclass        -0.243292    0.221009    0.081720    0.065997  \n",
       "Sex            0.082853    0.074115   -0.125722    0.200988  \n",
       "Age            0.269165   -0.118319   -0.165803    0.217052  \n",
       "Fare           0.269335   -0.117216   -0.166603    0.217138  \n",
       "Embarked_C     1.000000   -0.148258   -0.778359   -0.046215  \n",
       "Embarked_Q    -0.148258    1.000000   -0.496624   -0.058592  \n",
       "Embarked_S    -0.778359   -0.496624    1.000000    0.079977  \n",
       "FamilySize    -0.046215   -0.058592    0.079977    1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#相関係数チェック\n",
    "cv_train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#参考資料に乗っている相関チェック\n",
    "cv_train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Survived\n",
       "1    1  0.742038\n",
       "0    0  0.188908"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1b70b2550f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm0PyXahqkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(cv_train_data, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#　→年齢を子供、大人、老人で分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAKACAYAAACYK2DRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 700x648 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#年齢によってPclassごとの生存確率を確認\n",
    "#子供は生存しやすい\n",
    "#大人はPclass=1が生存しやすい\n",
    "#→年齢を子供、大人、老人で分ける\n",
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(cv_train_data, col='Survived', row='Pclass',  aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId   -0.005007\n",
       "Survived       1.000000\n",
       "Pclass        -0.338481\n",
       "Sex            0.543351\n",
       "Age            0.257482\n",
       "Fare           0.257307\n",
       "Embarked_C     0.168240\n",
       "Embarked_Q     0.003650\n",
       "Embarked_S    -0.155660\n",
       "FamilySize     0.016639\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data.corr()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相関係数で高いものをチェック\n",
      "Pclass:\n",
      " 0.221008919792132\n",
      "Sex:\n",
      " 0.5433513806577526\n",
      "Age:\n",
      " 0.9999791974608639\n",
      "Fare:\n",
      " 0.9999791974608639\n",
      "Embarked_C:\n",
      " 0.26933473491526394\n",
      "Embarked_Q:\n",
      " 0.221008919792132\n",
      "Embarked_S:\n",
      " 0.08172024174677404\n",
      "FamilySize:\n",
      " 0.21713840705243473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId   -0.042939\n",
       "Survived       0.543351\n",
       "Pclass        -0.131900\n",
       "Sex            1.000000\n",
       "Age            0.182331\n",
       "Fare           0.182333\n",
       "Embarked_C     0.082853\n",
       "Embarked_Q     0.074115\n",
       "Embarked_S    -0.125722\n",
       "FamilySize     0.200988\n",
       "Name: Sex, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('相関係数で高いものをチェック')\n",
    "print('Pclass:\\n',cv_train_data.corr()['Pclass'].drop('Pclass').max())\n",
    "print('Sex:\\n',cv_train_data.corr()['Sex'].drop('Sex').max())\n",
    "print('Age:\\n',cv_train_data.corr()['Age'].drop('Age').max())\n",
    "print('Fare:\\n',cv_train_data.corr()['Fare'].drop('Fare').max())\n",
    "print('Embarked_C:\\n',cv_train_data.corr()['Embarked_C'].drop('Embarked_C').max())\n",
    "print('Embarked_Q:\\n',cv_train_data.corr()['Embarked_Q'].drop('Embarked_Q').max())\n",
    "print('Embarked_S:\\n',cv_train_data.corr()['Embarked_S'].drop('Embarked_S').max())\n",
    "print('FamilySize:\\n',cv_train_data.corr()['FamilySize'].drop('FamilySize').max())\n",
    "\n",
    "#sexが高かったので確認\n",
    "cv_train_data.corr()['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       71\n",
       "27     263\n",
       "31     146\n",
       "34      82\n",
       "52      76\n",
       "61      80\n",
       "62      83\n",
       "72      73\n",
       "88     263\n",
       "102     77\n",
       "118    247\n",
       "120     73\n",
       "124     77\n",
       "139     79\n",
       "151     66\n",
       "159     69\n",
       "180     69\n",
       "195    146\n",
       "201     69\n",
       "215    113\n",
       "218     76\n",
       "224     90\n",
       "230     83\n",
       "245     90\n",
       "256     79\n",
       "257     86\n",
       "258    512\n",
       "262     79\n",
       "268    153\n",
       "269    135\n",
       "      ... \n",
       "660    133\n",
       "665     73\n",
       "679    512\n",
       "681     76\n",
       "689    211\n",
       "698    110\n",
       "700    227\n",
       "708    151\n",
       "716    227\n",
       "730    211\n",
       "737    512\n",
       "741     78\n",
       "742    262\n",
       "745     71\n",
       "754     65\n",
       "759     86\n",
       "763    120\n",
       "765     77\n",
       "779    211\n",
       "789     79\n",
       "792     69\n",
       "802    120\n",
       "820     93\n",
       "829     80\n",
       "835     83\n",
       "846     69\n",
       "849     89\n",
       "856    164\n",
       "863     69\n",
       "879     83\n",
       "Name: Age, Length: 118, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#年齢をbindする\n",
    "cv_train_data.loc[ cv_train_data['Age'] <= 16, 'Age'] = 0\n",
    "cv_train_data.loc[(cv_train_data['Age'] > 16) & (cv_train_data['Age'] <= 32), 'Age'] = 1\n",
    "cv_train_data.loc[(cv_train_data['Age'] > 32) & (cv_train_data['Age'] <= 48), 'Age'] = 2\n",
    "cv_train_data.loc[(cv_train_data['Age'] > 48) & (cv_train_data['Age'] <= 64), 'Age'] = 3\n",
    "cv_train_data.loc[ cv_train_data['Age'] > 64, 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12      82\n",
       "24     262\n",
       "48      76\n",
       "53     263\n",
       "59     262\n",
       "64     262\n",
       "69     263\n",
       "74     211\n",
       "75     211\n",
       "81     221\n",
       "96      78\n",
       "114    221\n",
       "118     75\n",
       "141    151\n",
       "142    262\n",
       "150     83\n",
       "156    221\n",
       "179     83\n",
       "181     83\n",
       "184    247\n",
       "188     69\n",
       "196    134\n",
       "202    227\n",
       "212     73\n",
       "217    164\n",
       "218    211\n",
       "230     65\n",
       "234     71\n",
       "236     75\n",
       "239    106\n",
       "242    134\n",
       "252    136\n",
       "270     75\n",
       "272    136\n",
       "287     82\n",
       "293     81\n",
       "306    151\n",
       "308     93\n",
       "314    135\n",
       "316    146\n",
       "324    211\n",
       "327     79\n",
       "342     69\n",
       "343    512\n",
       "352     73\n",
       "353     65\n",
       "360     69\n",
       "365     69\n",
       "371    134\n",
       "374     81\n",
       "375    262\n",
       "385     65\n",
       "390     93\n",
       "397     79\n",
       "400    164\n",
       "407    211\n",
       "411     90\n",
       "414    108\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#年齢をbindする\n",
    "cv_test_data.loc[ cv_test_data['Age'] <= 16, 'Age'] = 0\n",
    "cv_test_data.loc[(cv_test_data['Age'] > 16) & (cv_test_data['Age'] <= 32), 'Age'] = 1\n",
    "cv_test_data.loc[(cv_test_data['Age'] > 32) & (cv_test_data['Age'] <= 48), 'Age'] = 2\n",
    "cv_test_data.loc[(cv_test_data['Age'] > 48) & (cv_test_data['Age'] <= 64), 'Age'] = 3\n",
    "cv_test_data.loc[ cv_test_data['Age'] > 64, 'Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.040143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.155660</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.467932</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169894</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.125722</td>\n",
       "      <td>0.200988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>-0.467932</td>\n",
       "      <td>0.169894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969301</td>\n",
       "      <td>0.258043</td>\n",
       "      <td>-0.086488</td>\n",
       "      <td>-0.177180</td>\n",
       "      <td>0.151867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.969301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.166603</td>\n",
       "      <td>0.217138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.001205</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.258043</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.778359</td>\n",
       "      <td>-0.046215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.086488</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.496624</td>\n",
       "      <td>-0.058592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.155660</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>-0.125722</td>\n",
       "      <td>-0.177180</td>\n",
       "      <td>-0.166603</td>\n",
       "      <td>-0.778359</td>\n",
       "      <td>-0.496624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>0.151867</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.079977</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Sex       Age      Fare  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144 -0.042939  0.014097  0.012658   \n",
       "Survived       -0.005007  1.000000 -0.338481  0.543351  0.223576  0.257307   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.131900 -0.467932 -0.549500   \n",
       "Sex            -0.042939  0.543351 -0.131900  1.000000  0.169894  0.182333   \n",
       "Age             0.014097  0.223576 -0.467932  0.169894  1.000000  0.969301   \n",
       "Fare            0.012658  0.257307 -0.549500  0.182333  0.969301  1.000000   \n",
       "Embarked_C     -0.001205  0.168240 -0.243292  0.082853  0.258043  0.269335   \n",
       "Embarked_Q     -0.033606  0.003650  0.221009  0.074115 -0.086488 -0.117216   \n",
       "Embarked_S      0.022148 -0.155660  0.081720 -0.125722 -0.177180 -0.166603   \n",
       "FamilySize     -0.040143  0.016639  0.065997  0.200988  0.151867  0.217138   \n",
       "\n",
       "             Embarked_C  Embarked_Q  Embarked_S  FamilySize  \n",
       "PassengerId   -0.001205   -0.033606    0.022148   -0.040143  \n",
       "Survived       0.168240    0.003650   -0.155660    0.016639  \n",
       "Pclass        -0.243292    0.221009    0.081720    0.065997  \n",
       "Sex            0.082853    0.074115   -0.125722    0.200988  \n",
       "Age            0.258043   -0.086488   -0.177180    0.151867  \n",
       "Fare           0.269335   -0.117216   -0.166603    0.217138  \n",
       "Embarked_C     1.000000   -0.148258   -0.778359   -0.046215  \n",
       "Embarked_Q    -0.148258    1.000000   -0.496624   -0.058592  \n",
       "Embarked_S    -0.778359   -0.496624    1.000000    0.079977  \n",
       "FamilySize    -0.046215   -0.058592    0.079977    1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age     Fare  Embarked_C  Embarked_Q  \\\n",
       "0            1         0       3    0    0   7.2500           0           0   \n",
       "1            2         1       1    1   71  71.2833           1           0   \n",
       "2            3         1       3    1    0   7.9250           0           0   \n",
       "3            4         1       1    1    3  53.1000           0           0   \n",
       "4            5         0       3    0    0   8.0500           0           0   \n",
       "\n",
       "   Embarked_S  FamilySize  \n",
       "0           1           1  \n",
       "1           0           1  \n",
       "2           1           0  \n",
       "3           1           1  \n",
       "4           1           0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Age*Pclassを特徴量として置く\n",
    "if 'Age*Pclass' not in cv_train_data.columns:\n",
    "    cv_train_data['Age*Pclass']=cv_train_data['Age']*cv_train_data['Pclass']\n",
    "    \n",
    "if 'Age*Pclass' not in cv_test_data.columns:\n",
    "    cv_test_data['Age*Pclass']=cv_test_data['Age']*cv_test_data['Pclass']\n",
    "\n",
    "if 'Age' in cv_train_data.columns:\n",
    "    cv_train_data=cv_train_data.drop(columns=['Age'])\n",
    "    cv_train_data=cv_train_data.drop(columns=['Pclass'])\n",
    "\n",
    "if 'Age' in cv_test_data.columns:\n",
    "    cv_test_data=cv_test_data.drop(columns=['Age'])\n",
    "    cv_test_data=cv_test_data.drop(columns=['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex     Fare  Embarked_C  Embarked_Q  Embarked_S  FamilySize  Age*Pclass\n",
       "0    0   7.8292           0           1           0           0           0\n",
       "1    1   7.0000           0           0           1           1           0\n",
       "2    0   9.6875           0           1           0           0           0\n",
       "3    0   8.6625           0           0           1           0           0\n",
       "4    1  12.2875           0           0           1           2           0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>35.560915</td>\n",
       "      <td>0.244019</td>\n",
       "      <td>0.110048</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.839713</td>\n",
       "      <td>22.990431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.481622</td>\n",
       "      <td>55.856937</td>\n",
       "      <td>0.430019</td>\n",
       "      <td>0.313324</td>\n",
       "      <td>0.478803</td>\n",
       "      <td>1.519072</td>\n",
       "      <td>62.744428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.471875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>512.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sex        Fare  Embarked_C  Embarked_Q  Embarked_S  FamilySize  \\\n",
       "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000   \n",
       "mean     0.363636   35.560915    0.244019    0.110048    0.645933    0.839713   \n",
       "std      0.481622   55.856937    0.430019    0.313324    0.478803    1.519072   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    7.895800    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   14.454200    0.000000    0.000000    1.000000    0.000000   \n",
       "75%      1.000000   31.471875    0.000000    0.000000    1.000000    1.000000   \n",
       "max      1.000000  512.329200    1.000000    1.000000    1.000000   10.000000   \n",
       "\n",
       "       Age*Pclass  \n",
       "count  418.000000  \n",
       "mean    22.990431  \n",
       "std     62.744428  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      3.000000  \n",
       "max    512.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#目的変数と説明変数を分ける\n",
    "cv_train_data_x=cv_train_data.iloc[:,2:]\n",
    "\n",
    "cv_train_data_y=cv_train_data['Survived'].values\n",
    "cv_train_y_onehot = pd.get_dummies(cv_train_data['Survived']).values\n",
    "\n",
    "cv_train_data_y=pd.DataFrame(cv_train_data_y)\n",
    "cv_train_y_onehot=pd.DataFrame(cv_train_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.352413</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "      <td>0.904602</td>\n",
       "      <td>19.276094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477990</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "      <td>1.613459</td>\n",
       "      <td>55.815226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>512.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sex        Fare  Embarked_C  Embarked_Q  Embarked_S  FamilySize  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.352413   32.204208    0.188552    0.086420    0.722783    0.904602   \n",
       "std      0.477990   49.693429    0.391372    0.281141    0.447876    1.613459   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    7.910400    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   14.454200    0.000000    0.000000    1.000000    0.000000   \n",
       "75%      1.000000   31.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "max      1.000000  512.329200    1.000000    1.000000    1.000000   10.000000   \n",
       "\n",
       "       Age*Pclass  \n",
       "count  891.000000  \n",
       "mean    19.276094  \n",
       "std     55.815226  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      3.000000  \n",
       "max    512.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  891.000000\n",
       "mean     0.383838\n",
       "std      0.486592\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex     Fare  Embarked_C  Embarked_Q  Embarked_S  FamilySize  Age*Pclass\n",
       "0    0   7.2500           0           0           1           1           0\n",
       "1    1  71.2833           1           0           0           1          71\n",
       "2    1   7.9250           0           0           1           0           0\n",
       "3    1  53.1000           0           0           1           1           3\n",
       "4    0   8.0500           0           0           1           0           0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_data_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_num=4\n",
    "skf = StratifiedKFold(n_splits=split_num)\n",
    "skf.get_n_splits(cv_train_data_x, cv_train_data_y.values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [212 213 214 217 219 221 222 223 225 227 228 229 231 232 234 235 236 238\n",
      " 239 240 242 243 244 245 246 249 250 251 252 253 254 255 256 257 258 259\n",
      " 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277\n",
      " 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295\n",
      " 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313\n",
      " 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331\n",
      " 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349\n",
      " 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367\n",
      " 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385\n",
      " 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403\n",
      " 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421\n",
      " 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439\n",
      " 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457\n",
      " 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475\n",
      " 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      " 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511\n",
      " 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529\n",
      " 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547\n",
      " 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565\n",
      " 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583\n",
      " 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601\n",
      " 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619\n",
      " 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637\n",
      " 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655\n",
      " 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673\n",
      " 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691\n",
      " 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709\n",
      " 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727\n",
      " 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745\n",
      " 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763\n",
      " 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781\n",
      " 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799\n",
      " 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817\n",
      " 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835\n",
      " 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853\n",
      " 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871\n",
      " 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889\n",
      " 890] test: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 215 216 218 220\n",
      " 224 226 230 233 237 241 247 248]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 215 216 218 220\n",
      " 224 226 230 233 237 241 247 248 443 444 445 446 447 448 449 453 455 456\n",
      " 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474\n",
      " 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492\n",
      " 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510\n",
      " 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528\n",
      " 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546\n",
      " 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564\n",
      " 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582\n",
      " 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600\n",
      " 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618\n",
      " 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636\n",
      " 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654\n",
      " 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672\n",
      " 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690\n",
      " 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708\n",
      " 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726\n",
      " 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744\n",
      " 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762\n",
      " 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780\n",
      " 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798\n",
      " 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816\n",
      " 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834\n",
      " 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852\n",
      " 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870\n",
      " 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888\n",
      " 889 890] test: [212 213 214 217 219 221 222 223 225 227 228 229 231 232 234 235 236 238\n",
      " 239 240 242 243 244 245 246 249 250 251 252 253 254 255 256 257 258 259\n",
      " 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277\n",
      " 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295\n",
      " 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313\n",
      " 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331\n",
      " 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349\n",
      " 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367\n",
      " 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385\n",
      " 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403\n",
      " 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421\n",
      " 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439\n",
      " 440 441 442 450 451 452 454]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 450 451 452 454 653 660 664\n",
      " 669 670 673 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689\n",
      " 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707\n",
      " 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725\n",
      " 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743\n",
      " 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761\n",
      " 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779\n",
      " 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797\n",
      " 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815\n",
      " 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833\n",
      " 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851\n",
      " 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869\n",
      " 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887\n",
      " 888 889 890] test: [443 444 445 446 447 448 449 453 455 456 457 458 459 460 461 462 463 464\n",
      " 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482\n",
      " 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500\n",
      " 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518\n",
      " 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536\n",
      " 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554\n",
      " 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572\n",
      " 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590\n",
      " 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608\n",
      " 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626\n",
      " 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644\n",
      " 645 646 647 648 649 650 651 652 654 655 656 657 658 659 661 662 663 665\n",
      " 666 667 668 671 672 674]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 654 655 656 657 658 659 661 662 663 665 666 667 668\n",
      " 671 672 674] test: [653 660 664 669 670 673 675 676 677 678 679 680 681 682 683 684 685 686\n",
      " 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704\n",
      " 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722\n",
      " 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740\n",
      " 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758\n",
      " 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776\n",
      " 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794\n",
      " 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812\n",
      " 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830\n",
      " 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848\n",
      " 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866\n",
      " 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884\n",
      " 885 886 887 888 889 890]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for train_index, eva_index in skf.split(cv_train_data_x, cv_train_data_y.values):\n",
    "    print('train:',train_index,'test:',eva_index)\n",
    "    cv_train_x=cv_train_data_x.iloc[train_index,:]\n",
    "    cv_train_y=cv_train_data_y.iloc[train_index,:]\n",
    "    \n",
    "    cv_eva_x=cv_train_data_x.iloc[eva_index,:]\n",
    "    cv_eva_y=cv_train_data_y.iloc[eva_index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_train_y_onehot = pd.get_dummies(cv_train_y[0]).values\n",
    "cv_train_y_onehot=pd.DataFrame(cv_train_y_onehot)\n",
    "cv_eva_y_onehot = pd.get_dummies(cv_eva_y[0]).values\n",
    "cv_eva_y_onehot=pd.DataFrame(cv_eva_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    0  1\n",
       "3    0  1\n",
       "4    1  0\n",
       "5    1  0\n",
       "6    1  0\n",
       "7    1  0\n",
       "8    0  1\n",
       "9    0  1\n",
       "10   0  1\n",
       "11   0  1\n",
       "12   1  0\n",
       "13   1  0\n",
       "14   1  0\n",
       "15   0  1\n",
       "16   1  0\n",
       "17   0  1\n",
       "18   1  0\n",
       "19   0  1\n",
       "20   1  0\n",
       "21   0  1\n",
       "22   0  1\n",
       "23   0  1\n",
       "24   1  0\n",
       "25   0  1\n",
       "26   1  0\n",
       "27   1  0\n",
       "28   0  1\n",
       "29   1  0\n",
       "..  .. ..\n",
       "639  1  0\n",
       "640  1  0\n",
       "641  0  1\n",
       "642  1  0\n",
       "643  0  1\n",
       "644  0  1\n",
       "645  0  1\n",
       "646  1  0\n",
       "647  0  1\n",
       "648  1  0\n",
       "649  0  1\n",
       "650  1  0\n",
       "651  0  1\n",
       "652  1  0\n",
       "653  1  0\n",
       "654  1  0\n",
       "655  1  0\n",
       "656  1  0\n",
       "657  1  0\n",
       "658  1  0\n",
       "659  1  0\n",
       "660  1  0\n",
       "661  1  0\n",
       "662  1  0\n",
       "663  1  0\n",
       "664  1  0\n",
       "665  1  0\n",
       "666  1  0\n",
       "667  1  0\n",
       "668  1  0\n",
       "\n",
       "[669 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#データの標準化\n",
    "#特徴量の尺度を揃えなさい、揃え方には正規化と標準化があり、多くの機械学習アルゴリズムでは標準化が実用的\n",
    "tmp_x_columns=cv_train_x\n",
    "\n",
    "cv_train_x = scaler.fit_transform(cv_train_x[features].values)\n",
    "cv_eva_x = scaler.fit_transform(cv_eva_x[features].values)\n",
    "cv_train_x=pd.DataFrame(cv_train_x)\n",
    "cv_eva_x=pd.DataFrame(cv_eva_x)\n",
    "\n",
    "cv_train_x.columns = tmp_x_columns.columns\n",
    "cv_eva_x.columns = tmp_x_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#テストデータの正規化\n",
    "tmp_x_columns=cv_test_data\n",
    "\n",
    "cv_test_data = scaler.fit_transform(cv_test_data[features].values)\n",
    "cv_test_data=pd.DataFrame(cv_test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.965726e-18</td>\n",
       "      <td>-8.762298e-17</td>\n",
       "      <td>-7.434677e-17</td>\n",
       "      <td>-7.965726e-17</td>\n",
       "      <td>1.460383e-17</td>\n",
       "      <td>-5.310484e-18</td>\n",
       "      <td>8.496774e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000748e+00</td>\n",
       "      <td>1.000748e+00</td>\n",
       "      <td>1.000748e+00</td>\n",
       "      <td>1.000748e+00</td>\n",
       "      <td>1.000748e+00</td>\n",
       "      <td>1.000748e+00</td>\n",
       "      <td>1.000748e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.579471e-01</td>\n",
       "      <td>-7.528245e-01</td>\n",
       "      <td>-5.776971e-01</td>\n",
       "      <td>-6.993948e-01</td>\n",
       "      <td>-4.864143e-01</td>\n",
       "      <td>-3.138824e-01</td>\n",
       "      <td>-1.593638e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.579471e-01</td>\n",
       "      <td>-7.528245e-01</td>\n",
       "      <td>-5.776971e-01</td>\n",
       "      <td>-5.221188e-01</td>\n",
       "      <td>-4.864143e-01</td>\n",
       "      <td>-3.138824e-01</td>\n",
       "      <td>-1.593638e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.579471e-01</td>\n",
       "      <td>-7.528245e-01</td>\n",
       "      <td>-5.776971e-01</td>\n",
       "      <td>-3.750412e-01</td>\n",
       "      <td>-4.864143e-01</td>\n",
       "      <td>-3.138824e-01</td>\n",
       "      <td>6.274950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.988731e-01</td>\n",
       "      <td>1.328331e+00</td>\n",
       "      <td>5.900696e-02</td>\n",
       "      <td>-1.713383e-02</td>\n",
       "      <td>-4.864143e-01</td>\n",
       "      <td>-3.138824e-01</td>\n",
       "      <td>6.274950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.724030e+00</td>\n",
       "      <td>1.328331e+00</td>\n",
       "      <td>5.789344e+00</td>\n",
       "      <td>1.076101e+01</td>\n",
       "      <td>2.055861e+00</td>\n",
       "      <td>3.185906e+00</td>\n",
       "      <td>6.274950e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sex          Fare    Embarked_C    Embarked_Q    Embarked_S  \\\n",
       "count  6.690000e+02  6.690000e+02  6.690000e+02  6.690000e+02  6.690000e+02   \n",
       "mean   7.965726e-18 -8.762298e-17 -7.434677e-17 -7.965726e-17  1.460383e-17   \n",
       "std    1.000748e+00  1.000748e+00  1.000748e+00  1.000748e+00  1.000748e+00   \n",
       "min   -3.579471e-01 -7.528245e-01 -5.776971e-01 -6.993948e-01 -4.864143e-01   \n",
       "25%   -3.579471e-01 -7.528245e-01 -5.776971e-01 -5.221188e-01 -4.864143e-01   \n",
       "50%   -3.579471e-01 -7.528245e-01 -5.776971e-01 -3.750412e-01 -4.864143e-01   \n",
       "75%   -2.988731e-01  1.328331e+00  5.900696e-02 -1.713383e-02 -4.864143e-01   \n",
       "max    9.724030e+00  1.328331e+00  5.789344e+00  1.076101e+01  2.055861e+00   \n",
       "\n",
       "         FamilySize    Age*Pclass  \n",
       "count  6.690000e+02  6.690000e+02  \n",
       "mean  -5.310484e-18  8.496774e-17  \n",
       "std    1.000748e+00  1.000748e+00  \n",
       "min   -3.138824e-01 -1.593638e+00  \n",
       "25%   -3.138824e-01 -1.593638e+00  \n",
       "50%   -3.138824e-01  6.274950e-01  \n",
       "75%   -3.138824e-01  6.274950e-01  \n",
       "max    3.185906e+00  6.274950e-01  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>669.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.384155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  669.000000\n",
       "mean     0.384155\n",
       "std      0.486759\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.220000e+02</td>\n",
       "      <td>2.220000e+02</td>\n",
       "      <td>2.220000e+02</td>\n",
       "      <td>2.220000e+02</td>\n",
       "      <td>2.220000e+02</td>\n",
       "      <td>2.220000e+02</td>\n",
       "      <td>2.220000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.201447e-17</td>\n",
       "      <td>-8.801768e-17</td>\n",
       "      <td>4.800964e-17</td>\n",
       "      <td>9.601929e-17</td>\n",
       "      <td>7.201447e-17</td>\n",
       "      <td>1.020205e-16</td>\n",
       "      <td>2.800563e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002260e+00</td>\n",
       "      <td>1.002260e+00</td>\n",
       "      <td>1.002260e+00</td>\n",
       "      <td>1.002260e+00</td>\n",
       "      <td>1.002260e+00</td>\n",
       "      <td>1.002260e+00</td>\n",
       "      <td>1.002260e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.293383e-01</td>\n",
       "      <td>-6.928203e-01</td>\n",
       "      <td>-5.172951e-01</td>\n",
       "      <td>-5.633497e-01</td>\n",
       "      <td>-4.688072e-01</td>\n",
       "      <td>-2.879702e-01</td>\n",
       "      <td>-1.681543e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.293383e-01</td>\n",
       "      <td>-6.928203e-01</td>\n",
       "      <td>-5.172951e-01</td>\n",
       "      <td>-4.363760e-01</td>\n",
       "      <td>-4.688072e-01</td>\n",
       "      <td>-2.879702e-01</td>\n",
       "      <td>-1.681543e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.293383e-01</td>\n",
       "      <td>-6.928203e-01</td>\n",
       "      <td>-5.172951e-01</td>\n",
       "      <td>-3.542946e-01</td>\n",
       "      <td>-4.688072e-01</td>\n",
       "      <td>-2.879702e-01</td>\n",
       "      <td>5.946920e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.855929e-01</td>\n",
       "      <td>1.443376e+00</td>\n",
       "      <td>5.978788e-02</td>\n",
       "      <td>-3.960621e-02</td>\n",
       "      <td>-4.688072e-01</td>\n",
       "      <td>-2.879702e-01</td>\n",
       "      <td>5.946920e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.136539e+00</td>\n",
       "      <td>1.443376e+00</td>\n",
       "      <td>5.253535e+00</td>\n",
       "      <td>7.675502e+00</td>\n",
       "      <td>2.133073e+00</td>\n",
       "      <td>3.472582e+00</td>\n",
       "      <td>5.946920e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sex          Fare    Embarked_C    Embarked_Q    Embarked_S  \\\n",
       "count  2.220000e+02  2.220000e+02  2.220000e+02  2.220000e+02  2.220000e+02   \n",
       "mean  -7.201447e-17 -8.801768e-17  4.800964e-17  9.601929e-17  7.201447e-17   \n",
       "std    1.002260e+00  1.002260e+00  1.002260e+00  1.002260e+00  1.002260e+00   \n",
       "min   -3.293383e-01 -6.928203e-01 -5.172951e-01 -5.633497e-01 -4.688072e-01   \n",
       "25%   -3.293383e-01 -6.928203e-01 -5.172951e-01 -4.363760e-01 -4.688072e-01   \n",
       "50%   -3.293383e-01 -6.928203e-01 -5.172951e-01 -3.542946e-01 -4.688072e-01   \n",
       "75%   -2.855929e-01  1.443376e+00  5.978788e-02 -3.960621e-02 -4.688072e-01   \n",
       "max    7.136539e+00  1.443376e+00  5.253535e+00  7.675502e+00  2.133073e+00   \n",
       "\n",
       "         FamilySize    Age*Pclass  \n",
       "count  2.220000e+02  2.220000e+02  \n",
       "mean   1.020205e-16  2.800563e-17  \n",
       "std    1.002260e+00  1.002260e+00  \n",
       "min   -2.879702e-01 -1.681543e+00  \n",
       "25%   -2.879702e-01 -1.681543e+00  \n",
       "50%   -2.879702e-01  5.946920e-01  \n",
       "75%   -2.879702e-01  5.946920e-01  \n",
       "max    3.472582e+00  5.946920e-01  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_eva_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.382883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.487189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  222.000000\n",
       "mean     0.382883\n",
       "std      0.487189\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_eva_y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.235696\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[2]\tvalid_0's l2: 0.235127\n",
      "[3]\tvalid_0's l2: 0.234549\n",
      "[4]\tvalid_0's l2: 0.233983\n",
      "[5]\tvalid_0's l2: 0.233408\n",
      "[6]\tvalid_0's l2: 0.232854\n",
      "[7]\tvalid_0's l2: 0.23229\n",
      "[8]\tvalid_0's l2: 0.231739\n",
      "[9]\tvalid_0's l2: 0.231179\n",
      "[10]\tvalid_0's l2: 0.230627\n",
      "[11]\tvalid_0's l2: 0.23009\n",
      "[12]\tvalid_0's l2: 0.229558\n",
      "[13]\tvalid_0's l2: 0.229025\n",
      "[14]\tvalid_0's l2: 0.228483\n",
      "[15]\tvalid_0's l2: 0.227973\n",
      "[16]\tvalid_0's l2: 0.227441\n",
      "[17]\tvalid_0's l2: 0.226913\n",
      "[18]\tvalid_0's l2: 0.226397\n",
      "[19]\tvalid_0's l2: 0.225889\n",
      "[20]\tvalid_0's l2: 0.225379\n",
      "[21]\tvalid_0's l2: 0.224864\n",
      "[22]\tvalid_0's l2: 0.224378\n",
      "[23]\tvalid_0's l2: 0.223869\n",
      "[24]\tvalid_0's l2: 0.223373\n",
      "[25]\tvalid_0's l2: 0.222884\n",
      "[26]\tvalid_0's l2: 0.222382\n",
      "[27]\tvalid_0's l2: 0.221898\n",
      "[28]\tvalid_0's l2: 0.221419\n",
      "[29]\tvalid_0's l2: 0.220942\n",
      "[30]\tvalid_0's l2: 0.220453\n",
      "[31]\tvalid_0's l2: 0.219978\n",
      "[32]\tvalid_0's l2: 0.219511\n",
      "[33]\tvalid_0's l2: 0.219035\n",
      "[34]\tvalid_0's l2: 0.218573\n",
      "[35]\tvalid_0's l2: 0.218115\n",
      "[36]\tvalid_0's l2: 0.217656\n",
      "[37]\tvalid_0's l2: 0.217191\n",
      "[38]\tvalid_0's l2: 0.216752\n",
      "[39]\tvalid_0's l2: 0.21629\n",
      "[40]\tvalid_0's l2: 0.215843\n",
      "[41]\tvalid_0's l2: 0.2154\n",
      "[42]\tvalid_0's l2: 0.214951\n",
      "[43]\tvalid_0's l2: 0.214512\n",
      "[44]\tvalid_0's l2: 0.214068\n",
      "[45]\tvalid_0's l2: 0.213649\n",
      "[46]\tvalid_0's l2: 0.213183\n",
      "[47]\tvalid_0's l2: 0.21273\n",
      "[48]\tvalid_0's l2: 0.212307\n",
      "[49]\tvalid_0's l2: 0.211859\n",
      "[50]\tvalid_0's l2: 0.211405\n",
      "[51]\tvalid_0's l2: 0.210976\n",
      "[52]\tvalid_0's l2: 0.210539\n",
      "[53]\tvalid_0's l2: 0.210102\n",
      "[54]\tvalid_0's l2: 0.209681\n",
      "[55]\tvalid_0's l2: 0.209253\n",
      "[56]\tvalid_0's l2: 0.208825\n",
      "[57]\tvalid_0's l2: 0.208391\n",
      "[58]\tvalid_0's l2: 0.207981\n",
      "[59]\tvalid_0's l2: 0.207562\n",
      "[60]\tvalid_0's l2: 0.207145\n",
      "[61]\tvalid_0's l2: 0.206743\n",
      "[62]\tvalid_0's l2: 0.206335\n",
      "[63]\tvalid_0's l2: 0.205917\n",
      "[64]\tvalid_0's l2: 0.205523\n",
      "[65]\tvalid_0's l2: 0.20512\n",
      "[66]\tvalid_0's l2: 0.204719\n",
      "[67]\tvalid_0's l2: 0.204334\n",
      "[68]\tvalid_0's l2: 0.203941\n",
      "[69]\tvalid_0's l2: 0.203551\n",
      "[70]\tvalid_0's l2: 0.203149\n",
      "[71]\tvalid_0's l2: 0.202774\n",
      "[72]\tvalid_0's l2: 0.202389\n",
      "[73]\tvalid_0's l2: 0.202021\n",
      "[74]\tvalid_0's l2: 0.201653\n",
      "[75]\tvalid_0's l2: 0.201278\n",
      "[76]\tvalid_0's l2: 0.200904\n",
      "[77]\tvalid_0's l2: 0.200532\n",
      "[78]\tvalid_0's l2: 0.200162\n",
      "[79]\tvalid_0's l2: 0.199797\n",
      "[80]\tvalid_0's l2: 0.199446\n",
      "[81]\tvalid_0's l2: 0.199096\n",
      "[82]\tvalid_0's l2: 0.198736\n",
      "[83]\tvalid_0's l2: 0.198365\n",
      "[84]\tvalid_0's l2: 0.198021\n",
      "[85]\tvalid_0's l2: 0.197671\n",
      "[86]\tvalid_0's l2: 0.197334\n",
      "[87]\tvalid_0's l2: 0.196998\n",
      "[88]\tvalid_0's l2: 0.196652\n",
      "[89]\tvalid_0's l2: 0.196309\n",
      "[90]\tvalid_0's l2: 0.195966\n",
      "[91]\tvalid_0's l2: 0.195629\n",
      "[92]\tvalid_0's l2: 0.195306\n",
      "[93]\tvalid_0's l2: 0.194972\n",
      "[94]\tvalid_0's l2: 0.194651\n",
      "[95]\tvalid_0's l2: 0.194322\n",
      "[96]\tvalid_0's l2: 0.193994\n",
      "[97]\tvalid_0's l2: 0.19368\n",
      "[98]\tvalid_0's l2: 0.193359\n",
      "[99]\tvalid_0's l2: 0.193038\n",
      "[100]\tvalid_0's l2: 0.19273\n",
      "[101]\tvalid_0's l2: 0.192414\n",
      "[102]\tvalid_0's l2: 0.192087\n",
      "[103]\tvalid_0's l2: 0.191786\n",
      "[104]\tvalid_0's l2: 0.191478\n",
      "[105]\tvalid_0's l2: 0.191163\n",
      "[106]\tvalid_0's l2: 0.190859\n",
      "[107]\tvalid_0's l2: 0.190548\n",
      "[108]\tvalid_0's l2: 0.190248\n",
      "[109]\tvalid_0's l2: 0.189936\n",
      "[110]\tvalid_0's l2: 0.189632\n",
      "[111]\tvalid_0's l2: 0.189338\n",
      "[112]\tvalid_0's l2: 0.189038\n",
      "[113]\tvalid_0's l2: 0.188757\n",
      "[114]\tvalid_0's l2: 0.188461\n",
      "[115]\tvalid_0's l2: 0.188161\n",
      "[116]\tvalid_0's l2: 0.187869\n",
      "[117]\tvalid_0's l2: 0.187586\n",
      "[118]\tvalid_0's l2: 0.187298\n",
      "[119]\tvalid_0's l2: 0.18702\n",
      "[120]\tvalid_0's l2: 0.186735\n",
      "[121]\tvalid_0's l2: 0.186447\n",
      "[122]\tvalid_0's l2: 0.186183\n",
      "[123]\tvalid_0's l2: 0.185904\n",
      "[124]\tvalid_0's l2: 0.185635\n",
      "[125]\tvalid_0's l2: 0.18536\n",
      "[126]\tvalid_0's l2: 0.185095\n",
      "[127]\tvalid_0's l2: 0.184832\n",
      "[128]\tvalid_0's l2: 0.184556\n",
      "[129]\tvalid_0's l2: 0.184296\n",
      "[130]\tvalid_0's l2: 0.184039\n",
      "[131]\tvalid_0's l2: 0.183782\n",
      "[132]\tvalid_0's l2: 0.183527\n",
      "[133]\tvalid_0's l2: 0.183284\n",
      "[134]\tvalid_0's l2: 0.183047\n",
      "[135]\tvalid_0's l2: 0.182797\n",
      "[136]\tvalid_0's l2: 0.18255\n",
      "[137]\tvalid_0's l2: 0.182304\n",
      "[138]\tvalid_0's l2: 0.182051\n",
      "[139]\tvalid_0's l2: 0.181803\n",
      "[140]\tvalid_0's l2: 0.181576\n",
      "[141]\tvalid_0's l2: 0.18133\n",
      "[142]\tvalid_0's l2: 0.181094\n",
      "[143]\tvalid_0's l2: 0.180849\n",
      "[144]\tvalid_0's l2: 0.180607\n",
      "[145]\tvalid_0's l2: 0.180366\n",
      "[146]\tvalid_0's l2: 0.18015\n",
      "[147]\tvalid_0's l2: 0.179913\n",
      "[148]\tvalid_0's l2: 0.179678\n",
      "[149]\tvalid_0's l2: 0.179443\n",
      "[150]\tvalid_0's l2: 0.179213\n",
      "[151]\tvalid_0's l2: 0.178981\n",
      "[152]\tvalid_0's l2: 0.178782\n",
      "[153]\tvalid_0's l2: 0.178555\n",
      "[154]\tvalid_0's l2: 0.178327\n",
      "[155]\tvalid_0's l2: 0.178103\n",
      "[156]\tvalid_0's l2: 0.17788\n",
      "[157]\tvalid_0's l2: 0.177658\n",
      "[158]\tvalid_0's l2: 0.177436\n",
      "[159]\tvalid_0's l2: 0.177238\n",
      "[160]\tvalid_0's l2: 0.17702\n",
      "[161]\tvalid_0's l2: 0.176803\n",
      "[162]\tvalid_0's l2: 0.176587\n",
      "[163]\tvalid_0's l2: 0.176373\n",
      "[164]\tvalid_0's l2: 0.176161\n",
      "[165]\tvalid_0's l2: 0.175959\n",
      "[166]\tvalid_0's l2: 0.175772\n",
      "[167]\tvalid_0's l2: 0.175562\n",
      "[168]\tvalid_0's l2: 0.175356\n",
      "[169]\tvalid_0's l2: 0.175149\n",
      "[170]\tvalid_0's l2: 0.174944\n",
      "[171]\tvalid_0's l2: 0.174743\n",
      "[172]\tvalid_0's l2: 0.17454\n",
      "[173]\tvalid_0's l2: 0.174362\n",
      "[174]\tvalid_0's l2: 0.174163\n",
      "[175]\tvalid_0's l2: 0.173965\n",
      "[176]\tvalid_0's l2: 0.17377\n",
      "[177]\tvalid_0's l2: 0.173576\n",
      "[178]\tvalid_0's l2: 0.173381\n",
      "[179]\tvalid_0's l2: 0.173212\n",
      "[180]\tvalid_0's l2: 0.173022\n",
      "[181]\tvalid_0's l2: 0.17283\n",
      "[182]\tvalid_0's l2: 0.172671\n",
      "[183]\tvalid_0's l2: 0.172519\n",
      "[184]\tvalid_0's l2: 0.172333\n",
      "[185]\tvalid_0's l2: 0.172176\n",
      "[186]\tvalid_0's l2: 0.172024\n",
      "[187]\tvalid_0's l2: 0.171868\n",
      "[188]\tvalid_0's l2: 0.171685\n",
      "[189]\tvalid_0's l2: 0.171535\n",
      "[190]\tvalid_0's l2: 0.171381\n",
      "[191]\tvalid_0's l2: 0.171203\n",
      "[192]\tvalid_0's l2: 0.171057\n",
      "[193]\tvalid_0's l2: 0.170909\n",
      "[194]\tvalid_0's l2: 0.17076\n",
      "[195]\tvalid_0's l2: 0.170589\n",
      "[196]\tvalid_0's l2: 0.170445\n",
      "[197]\tvalid_0's l2: 0.170299\n",
      "[198]\tvalid_0's l2: 0.170139\n",
      "[199]\tvalid_0's l2: 0.169998\n",
      "[200]\tvalid_0's l2: 0.169857\n",
      "[201]\tvalid_0's l2: 0.169724\n",
      "[202]\tvalid_0's l2: 0.169559\n",
      "[203]\tvalid_0's l2: 0.169429\n",
      "[204]\tvalid_0's l2: 0.169292\n",
      "[205]\tvalid_0's l2: 0.16913\n",
      "[206]\tvalid_0's l2: 0.169003\n",
      "[207]\tvalid_0's l2: 0.168869\n",
      "[208]\tvalid_0's l2: 0.168711\n",
      "[209]\tvalid_0's l2: 0.168588\n",
      "[210]\tvalid_0's l2: 0.16844\n",
      "[211]\tvalid_0's l2: 0.168309\n",
      "[212]\tvalid_0's l2: 0.168162\n",
      "[213]\tvalid_0's l2: 0.168035\n",
      "[214]\tvalid_0's l2: 0.167891\n",
      "[215]\tvalid_0's l2: 0.167772\n",
      "[216]\tvalid_0's l2: 0.167621\n",
      "[217]\tvalid_0's l2: 0.167498\n",
      "[218]\tvalid_0's l2: 0.167365\n",
      "[219]\tvalid_0's l2: 0.167242\n",
      "[220]\tvalid_0's l2: 0.167096\n",
      "[221]\tvalid_0's l2: 0.166983\n",
      "[222]\tvalid_0's l2: 0.166863\n",
      "[223]\tvalid_0's l2: 0.166711\n",
      "[224]\tvalid_0's l2: 0.166604\n",
      "[225]\tvalid_0's l2: 0.166462\n",
      "[226]\tvalid_0's l2: 0.166356\n",
      "[227]\tvalid_0's l2: 0.166248\n",
      "[228]\tvalid_0's l2: 0.166109\n",
      "[229]\tvalid_0's l2: 0.166003\n",
      "[230]\tvalid_0's l2: 0.165899\n",
      "[231]\tvalid_0's l2: 0.165763\n",
      "[232]\tvalid_0's l2: 0.165646\n",
      "[233]\tvalid_0's l2: 0.165546\n",
      "[234]\tvalid_0's l2: 0.165445\n",
      "[235]\tvalid_0's l2: 0.165318\n",
      "[236]\tvalid_0's l2: 0.165205\n",
      "[237]\tvalid_0's l2: 0.165108\n",
      "[238]\tvalid_0's l2: 0.165009\n",
      "[239]\tvalid_0's l2: 0.164886\n",
      "[240]\tvalid_0's l2: 0.164777\n",
      "[241]\tvalid_0's l2: 0.164681\n",
      "[242]\tvalid_0's l2: 0.164562\n",
      "[243]\tvalid_0's l2: 0.164468\n",
      "[244]\tvalid_0's l2: 0.164376\n",
      "[245]\tvalid_0's l2: 0.164284\n",
      "[246]\tvalid_0's l2: 0.16416\n",
      "[247]\tvalid_0's l2: 0.164068\n",
      "[248]\tvalid_0's l2: 0.163965\n",
      "[249]\tvalid_0's l2: 0.163875\n",
      "[250]\tvalid_0's l2: 0.163763\n",
      "[251]\tvalid_0's l2: 0.163676\n",
      "[252]\tvalid_0's l2: 0.163589\n",
      "[253]\tvalid_0's l2: 0.16347\n",
      "[254]\tvalid_0's l2: 0.163384\n",
      "[255]\tvalid_0's l2: 0.163286\n",
      "[256]\tvalid_0's l2: 0.163201\n",
      "[257]\tvalid_0's l2: 0.163094\n",
      "[258]\tvalid_0's l2: 0.16301\n",
      "[259]\tvalid_0's l2: 0.162915\n",
      "[260]\tvalid_0's l2: 0.162833\n",
      "[261]\tvalid_0's l2: 0.162729\n",
      "[262]\tvalid_0's l2: 0.16265\n",
      "[263]\tvalid_0's l2: 0.16254\n",
      "[264]\tvalid_0's l2: 0.16246\n",
      "[265]\tvalid_0's l2: 0.162382\n",
      "[266]\tvalid_0's l2: 0.162292\n",
      "[267]\tvalid_0's l2: 0.162215\n",
      "[268]\tvalid_0's l2: 0.162116\n",
      "[269]\tvalid_0's l2: 0.16204\n",
      "[270]\tvalid_0's l2: 0.161934\n",
      "[271]\tvalid_0's l2: 0.161861\n",
      "[272]\tvalid_0's l2: 0.161787\n",
      "[273]\tvalid_0's l2: 0.161692\n",
      "[274]\tvalid_0's l2: 0.161606\n",
      "[275]\tvalid_0's l2: 0.161535\n",
      "[276]\tvalid_0's l2: 0.161463\n",
      "[277]\tvalid_0's l2: 0.161371\n",
      "[278]\tvalid_0's l2: 0.161288\n",
      "[279]\tvalid_0's l2: 0.161218\n",
      "[280]\tvalid_0's l2: 0.161129\n",
      "[281]\tvalid_0's l2: 0.161063\n",
      "[282]\tvalid_0's l2: 0.160984\n",
      "[283]\tvalid_0's l2: 0.160918\n",
      "[284]\tvalid_0's l2: 0.160832\n",
      "[285]\tvalid_0's l2: 0.160768\n",
      "[286]\tvalid_0's l2: 0.160692\n",
      "[287]\tvalid_0's l2: 0.160629\n",
      "[288]\tvalid_0's l2: 0.160545\n",
      "[289]\tvalid_0's l2: 0.160484\n",
      "[290]\tvalid_0's l2: 0.16041\n",
      "[291]\tvalid_0's l2: 0.16035\n",
      "[292]\tvalid_0's l2: 0.160268\n",
      "[293]\tvalid_0's l2: 0.160208\n",
      "[294]\tvalid_0's l2: 0.160149\n",
      "[295]\tvalid_0's l2: 0.16007\n",
      "[296]\tvalid_0's l2: 0.160013\n",
      "[297]\tvalid_0's l2: 0.159944\n",
      "[298]\tvalid_0's l2: 0.159887\n",
      "[299]\tvalid_0's l2: 0.159811\n",
      "[300]\tvalid_0's l2: 0.159757\n",
      "[301]\tvalid_0's l2: 0.15969\n",
      "[302]\tvalid_0's l2: 0.159635\n",
      "[303]\tvalid_0's l2: 0.159561\n",
      "[304]\tvalid_0's l2: 0.159509\n",
      "[305]\tvalid_0's l2: 0.159429\n",
      "[306]\tvalid_0's l2: 0.159377\n",
      "[307]\tvalid_0's l2: 0.159327\n",
      "[308]\tvalid_0's l2: 0.159265\n",
      "[309]\tvalid_0's l2: 0.159187\n",
      "[310]\tvalid_0's l2: 0.159138\n",
      "[311]\tvalid_0's l2: 0.159087\n",
      "[312]\tvalid_0's l2: 0.159018\n",
      "[313]\tvalid_0's l2: 0.158959\n",
      "[314]\tvalid_0's l2: 0.158912\n",
      "[315]\tvalid_0's l2: 0.158845\n",
      "[316]\tvalid_0's l2: 0.158799\n",
      "[317]\tvalid_0's l2: 0.158742\n",
      "[318]\tvalid_0's l2: 0.158697\n",
      "[319]\tvalid_0's l2: 0.158632\n",
      "[320]\tvalid_0's l2: 0.158586\n",
      "[321]\tvalid_0's l2: 0.158531\n",
      "[322]\tvalid_0's l2: 0.158488\n",
      "[323]\tvalid_0's l2: 0.158425\n",
      "[324]\tvalid_0's l2: 0.158384\n",
      "[325]\tvalid_0's l2: 0.158339\n",
      "[326]\tvalid_0's l2: 0.158298\n",
      "[327]\tvalid_0's l2: 0.158237\n",
      "[328]\tvalid_0's l2: 0.158177\n",
      "[329]\tvalid_0's l2: 0.158138\n",
      "[330]\tvalid_0's l2: 0.158088\n",
      "[331]\tvalid_0's l2: 0.158034\n",
      "[332]\tvalid_0's l2: 0.157976\n",
      "[333]\tvalid_0's l2: 0.157944\n",
      "[334]\tvalid_0's l2: 0.157891\n",
      "[335]\tvalid_0's l2: 0.157827\n",
      "[336]\tvalid_0's l2: 0.157777\n",
      "[337]\tvalid_0's l2: 0.157738\n",
      "[338]\tvalid_0's l2: 0.157701\n",
      "[339]\tvalid_0's l2: 0.157632\n",
      "[340]\tvalid_0's l2: 0.157568\n",
      "[341]\tvalid_0's l2: 0.157523\n",
      "[342]\tvalid_0's l2: 0.157478\n",
      "[343]\tvalid_0's l2: 0.157426\n",
      "[344]\tvalid_0's l2: 0.157383\n",
      "[345]\tvalid_0's l2: 0.157347\n",
      "[346]\tvalid_0's l2: 0.157304\n",
      "[347]\tvalid_0's l2: 0.157243\n",
      "[348]\tvalid_0's l2: 0.15719\n",
      "[349]\tvalid_0's l2: 0.157149\n",
      "[350]\tvalid_0's l2: 0.157117\n",
      "[351]\tvalid_0's l2: 0.157051\n",
      "[352]\tvalid_0's l2: 0.157022\n",
      "[353]\tvalid_0's l2: 0.156979\n",
      "[354]\tvalid_0's l2: 0.156949\n",
      "[355]\tvalid_0's l2: 0.156891\n",
      "[356]\tvalid_0's l2: 0.156843\n",
      "[357]\tvalid_0's l2: 0.15679\n",
      "[358]\tvalid_0's l2: 0.156742\n",
      "[359]\tvalid_0's l2: 0.156723\n",
      "[360]\tvalid_0's l2: 0.156651\n",
      "[361]\tvalid_0's l2: 0.156614\n",
      "[362]\tvalid_0's l2: 0.156567\n",
      "[363]\tvalid_0's l2: 0.156501\n",
      "[364]\tvalid_0's l2: 0.156476\n",
      "[365]\tvalid_0's l2: 0.156431\n",
      "[366]\tvalid_0's l2: 0.156388\n",
      "[367]\tvalid_0's l2: 0.156341\n",
      "[368]\tvalid_0's l2: 0.156299\n",
      "[369]\tvalid_0's l2: 0.156252\n",
      "[370]\tvalid_0's l2: 0.156209\n",
      "[371]\tvalid_0's l2: 0.156161\n",
      "[372]\tvalid_0's l2: 0.156126\n",
      "[373]\tvalid_0's l2: 0.156103\n",
      "[374]\tvalid_0's l2: 0.156053\n",
      "[375]\tvalid_0's l2: 0.156013\n",
      "[376]\tvalid_0's l2: 0.155948\n",
      "[377]\tvalid_0's l2: 0.155899\n",
      "[378]\tvalid_0's l2: 0.155869\n",
      "[379]\tvalid_0's l2: 0.155829\n",
      "[380]\tvalid_0's l2: 0.155798\n",
      "[381]\tvalid_0's l2: 0.15575\n",
      "[382]\tvalid_0's l2: 0.155703\n",
      "[383]\tvalid_0's l2: 0.155675\n",
      "[384]\tvalid_0's l2: 0.155618\n",
      "[385]\tvalid_0's l2: 0.155582\n",
      "[386]\tvalid_0's l2: 0.155544\n",
      "[387]\tvalid_0's l2: 0.155515\n",
      "[388]\tvalid_0's l2: 0.155469\n",
      "[389]\tvalid_0's l2: 0.155425\n",
      "[390]\tvalid_0's l2: 0.155399\n",
      "[391]\tvalid_0's l2: 0.155345\n",
      "[392]\tvalid_0's l2: 0.155328\n",
      "[393]\tvalid_0's l2: 0.155282\n",
      "[394]\tvalid_0's l2: 0.155238\n",
      "[395]\tvalid_0's l2: 0.155214\n",
      "[396]\tvalid_0's l2: 0.155162\n",
      "[397]\tvalid_0's l2: 0.155146\n",
      "[398]\tvalid_0's l2: 0.1551\n",
      "[399]\tvalid_0's l2: 0.155078\n",
      "[400]\tvalid_0's l2: 0.155036\n",
      "[401]\tvalid_0's l2: 0.154995\n",
      "[402]\tvalid_0's l2: 0.154963\n",
      "[403]\tvalid_0's l2: 0.15493\n",
      "[404]\tvalid_0's l2: 0.154906\n",
      "[405]\tvalid_0's l2: 0.154865\n",
      "[406]\tvalid_0's l2: 0.154825\n",
      "[407]\tvalid_0's l2: 0.154795\n",
      "[408]\tvalid_0's l2: 0.154763\n",
      "[409]\tvalid_0's l2: 0.15474\n",
      "[410]\tvalid_0's l2: 0.154701\n",
      "[411]\tvalid_0's l2: 0.154681\n",
      "[412]\tvalid_0's l2: 0.154643\n",
      "[413]\tvalid_0's l2: 0.154596\n",
      "[414]\tvalid_0's l2: 0.154584\n",
      "[415]\tvalid_0's l2: 0.154543\n",
      "[416]\tvalid_0's l2: 0.154525\n",
      "[417]\tvalid_0's l2: 0.154487\n",
      "[418]\tvalid_0's l2: 0.154469\n",
      "[419]\tvalid_0's l2: 0.154421\n",
      "[420]\tvalid_0's l2: 0.154386\n",
      "[421]\tvalid_0's l2: 0.154369\n",
      "[422]\tvalid_0's l2: 0.154322\n",
      "[423]\tvalid_0's l2: 0.154307\n",
      "[424]\tvalid_0's l2: 0.154271\n",
      "[425]\tvalid_0's l2: 0.154222\n",
      "[426]\tvalid_0's l2: 0.154206\n",
      "[427]\tvalid_0's l2: 0.154173\n",
      "[428]\tvalid_0's l2: 0.154158\n",
      "[429]\tvalid_0's l2: 0.15411\n",
      "[430]\tvalid_0's l2: 0.154096\n",
      "[431]\tvalid_0's l2: 0.154064\n",
      "[432]\tvalid_0's l2: 0.154016\n",
      "[433]\tvalid_0's l2: 0.154003\n",
      "[434]\tvalid_0's l2: 0.153971\n",
      "[435]\tvalid_0's l2: 0.153942\n",
      "[436]\tvalid_0's l2: 0.153911\n",
      "[437]\tvalid_0's l2: 0.15388\n",
      "[438]\tvalid_0's l2: 0.153866\n",
      "[439]\tvalid_0's l2: 0.153819\n",
      "[440]\tvalid_0's l2: 0.153808\n",
      "[441]\tvalid_0's l2: 0.153778\n",
      "[442]\tvalid_0's l2: 0.153751\n",
      "[443]\tvalid_0's l2: 0.153721\n",
      "[444]\tvalid_0's l2: 0.153692\n",
      "[445]\tvalid_0's l2: 0.153666\n",
      "[446]\tvalid_0's l2: 0.153636\n",
      "[447]\tvalid_0's l2: 0.153627\n",
      "[448]\tvalid_0's l2: 0.153597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[449]\tvalid_0's l2: 0.153572\n",
      "[450]\tvalid_0's l2: 0.153543\n",
      "[451]\tvalid_0's l2: 0.153514\n",
      "[452]\tvalid_0's l2: 0.153504\n",
      "[453]\tvalid_0's l2: 0.153474\n",
      "[454]\tvalid_0's l2: 0.153465\n",
      "[455]\tvalid_0's l2: 0.153437\n",
      "[456]\tvalid_0's l2: 0.153408\n",
      "[457]\tvalid_0's l2: 0.153399\n",
      "[458]\tvalid_0's l2: 0.153371\n",
      "[459]\tvalid_0's l2: 0.153362\n",
      "[460]\tvalid_0's l2: 0.153334\n",
      "[461]\tvalid_0's l2: 0.153326\n",
      "[462]\tvalid_0's l2: 0.153299\n",
      "[463]\tvalid_0's l2: 0.153286\n",
      "[464]\tvalid_0's l2: 0.153291\n",
      "[465]\tvalid_0's l2: 0.153273\n",
      "[466]\tvalid_0's l2: 0.153279\n",
      "[467]\tvalid_0's l2: 0.153266\n",
      "[468]\tvalid_0's l2: 0.153272\n",
      "[469]\tvalid_0's l2: 0.153255\n",
      "[470]\tvalid_0's l2: 0.153243\n",
      "[471]\tvalid_0's l2: 0.15325\n",
      "[472]\tvalid_0's l2: 0.153239\n",
      "[473]\tvalid_0's l2: 0.153246\n",
      "[474]\tvalid_0's l2: 0.153228\n",
      "[475]\tvalid_0's l2: 0.153218\n",
      "[476]\tvalid_0's l2: 0.153225\n",
      "[477]\tvalid_0's l2: 0.153215\n",
      "[478]\tvalid_0's l2: 0.153223\n",
      "[479]\tvalid_0's l2: 0.153211\n",
      "[480]\tvalid_0's l2: 0.153212\n",
      "[481]\tvalid_0's l2: 0.153206\n",
      "[482]\tvalid_0's l2: 0.153189\n",
      "[483]\tvalid_0's l2: 0.15319\n",
      "[484]\tvalid_0's l2: 0.153179\n",
      "[485]\tvalid_0's l2: 0.15318\n",
      "[486]\tvalid_0's l2: 0.153176\n",
      "[487]\tvalid_0's l2: 0.153177\n",
      "[488]\tvalid_0's l2: 0.153173\n",
      "[489]\tvalid_0's l2: 0.153151\n",
      "[490]\tvalid_0's l2: 0.153165\n",
      "[491]\tvalid_0's l2: 0.153148\n",
      "[492]\tvalid_0's l2: 0.153163\n",
      "[493]\tvalid_0's l2: 0.153129\n",
      "[494]\tvalid_0's l2: 0.153114\n",
      "[495]\tvalid_0's l2: 0.153129\n",
      "[496]\tvalid_0's l2: 0.153114\n",
      "[497]\tvalid_0's l2: 0.153123\n",
      "[498]\tvalid_0's l2: 0.153108\n",
      "[499]\tvalid_0's l2: 0.153123\n",
      "[500]\tvalid_0's l2: 0.153091\n",
      "[501]\tvalid_0's l2: 0.153088\n",
      "[502]\tvalid_0's l2: 0.153092\n",
      "[503]\tvalid_0's l2: 0.15309\n",
      "[504]\tvalid_0's l2: 0.153094\n",
      "[505]\tvalid_0's l2: 0.153061\n",
      "[506]\tvalid_0's l2: 0.153078\n",
      "[507]\tvalid_0's l2: 0.153066\n",
      "[508]\tvalid_0's l2: 0.153057\n",
      "[509]\tvalid_0's l2: 0.153062\n",
      "[510]\tvalid_0's l2: 0.153061\n",
      "[511]\tvalid_0's l2: 0.153066\n",
      "[512]\tvalid_0's l2: 0.153035\n",
      "[513]\tvalid_0's l2: 0.153034\n",
      "[514]\tvalid_0's l2: 0.153041\n",
      "[515]\tvalid_0's l2: 0.153033\n",
      "[516]\tvalid_0's l2: 0.153038\n",
      "[517]\tvalid_0's l2: 0.153038\n",
      "[518]\tvalid_0's l2: 0.153044\n",
      "[519]\tvalid_0's l2: 0.153043\n",
      "[520]\tvalid_0's l2: 0.153014\n",
      "[521]\tvalid_0's l2: 0.153021\n",
      "[522]\tvalid_0's l2: 0.153021\n",
      "[523]\tvalid_0's l2: 0.153025\n",
      "[524]\tvalid_0's l2: 0.153025\n",
      "[525]\tvalid_0's l2: 0.153044\n",
      "[526]\tvalid_0's l2: 0.153026\n",
      "[527]\tvalid_0's l2: 0.152998\n",
      "[528]\tvalid_0's l2: 0.153018\n",
      "[529]\tvalid_0's l2: 0.153019\n",
      "[530]\tvalid_0's l2: 0.153029\n",
      "[531]\tvalid_0's l2: 0.153024\n",
      "[532]\tvalid_0's l2: 0.153026\n",
      "[533]\tvalid_0's l2: 0.153027\n",
      "[534]\tvalid_0's l2: 0.153\n",
      "[535]\tvalid_0's l2: 0.15302\n",
      "[536]\tvalid_0's l2: 0.153004\n",
      "[537]\tvalid_0's l2: 0.153024\n",
      "[538]\tvalid_0's l2: 0.153009\n",
      "[539]\tvalid_0's l2: 0.152982\n",
      "[540]\tvalid_0's l2: 0.153002\n",
      "[541]\tvalid_0's l2: 0.152998\n",
      "[542]\tvalid_0's l2: 0.153001\n",
      "[543]\tvalid_0's l2: 0.153003\n",
      "[544]\tvalid_0's l2: 0.153023\n",
      "[545]\tvalid_0's l2: 0.153026\n",
      "[546]\tvalid_0's l2: 0.153022\n",
      "[547]\tvalid_0's l2: 0.153042\n",
      "[548]\tvalid_0's l2: 0.153045\n",
      "[549]\tvalid_0's l2: 0.153037\n",
      "[550]\tvalid_0's l2: 0.15304\n",
      "[551]\tvalid_0's l2: 0.153061\n",
      "[552]\tvalid_0's l2: 0.153053\n",
      "[553]\tvalid_0's l2: 0.153067\n",
      "[554]\tvalid_0's l2: 0.153058\n",
      "[555]\tvalid_0's l2: 0.153061\n",
      "[556]\tvalid_0's l2: 0.153075\n",
      "[557]\tvalid_0's l2: 0.153078\n",
      "[558]\tvalid_0's l2: 0.153093\n",
      "[559]\tvalid_0's l2: 0.153096\n",
      "[560]\tvalid_0's l2: 0.153112\n",
      "[561]\tvalid_0's l2: 0.153103\n",
      "[562]\tvalid_0's l2: 0.153118\n",
      "[563]\tvalid_0's l2: 0.153122\n",
      "[564]\tvalid_0's l2: 0.153138\n",
      "[565]\tvalid_0's l2: 0.153141\n",
      "[566]\tvalid_0's l2: 0.153157\n",
      "[567]\tvalid_0's l2: 0.153161\n",
      "[568]\tvalid_0's l2: 0.153154\n",
      "[569]\tvalid_0's l2: 0.15317\n",
      "[570]\tvalid_0's l2: 0.153175\n",
      "[571]\tvalid_0's l2: 0.153191\n",
      "[572]\tvalid_0's l2: 0.153196\n",
      "[573]\tvalid_0's l2: 0.153212\n",
      "[574]\tvalid_0's l2: 0.153217\n",
      "[575]\tvalid_0's l2: 0.153234\n",
      "[576]\tvalid_0's l2: 0.153239\n",
      "[577]\tvalid_0's l2: 0.153243\n",
      "[578]\tvalid_0's l2: 0.153248\n",
      "[579]\tvalid_0's l2: 0.153237\n",
      "[580]\tvalid_0's l2: 0.153255\n",
      "[581]\tvalid_0's l2: 0.153244\n",
      "[582]\tvalid_0's l2: 0.153262\n",
      "[583]\tvalid_0's l2: 0.153251\n",
      "[584]\tvalid_0's l2: 0.153252\n",
      "[585]\tvalid_0's l2: 0.153254\n",
      "[586]\tvalid_0's l2: 0.153268\n",
      "[587]\tvalid_0's l2: 0.153282\n",
      "[588]\tvalid_0's l2: 0.153263\n",
      "[589]\tvalid_0's l2: 0.153277\n",
      "[590]\tvalid_0's l2: 0.153267\n",
      "[591]\tvalid_0's l2: 0.153281\n",
      "[592]\tvalid_0's l2: 0.153263\n",
      "[593]\tvalid_0's l2: 0.153278\n",
      "[594]\tvalid_0's l2: 0.15326\n",
      "[595]\tvalid_0's l2: 0.153263\n",
      "[596]\tvalid_0's l2: 0.153266\n",
      "[597]\tvalid_0's l2: 0.153269\n",
      "[598]\tvalid_0's l2: 0.153263\n",
      "[599]\tvalid_0's l2: 0.153267\n",
      "[600]\tvalid_0's l2: 0.15325\n",
      "[601]\tvalid_0's l2: 0.153245\n",
      "[602]\tvalid_0's l2: 0.153236\n",
      "[603]\tvalid_0's l2: 0.15324\n",
      "[604]\tvalid_0's l2: 0.15326\n",
      "[605]\tvalid_0's l2: 0.153243\n",
      "[606]\tvalid_0's l2: 0.153247\n",
      "[607]\tvalid_0's l2: 0.15324\n",
      "[608]\tvalid_0's l2: 0.153231\n",
      "[609]\tvalid_0's l2: 0.153236\n",
      "[610]\tvalid_0's l2: 0.153253\n",
      "[611]\tvalid_0's l2: 0.153257\n",
      "[612]\tvalid_0's l2: 0.153239\n",
      "[613]\tvalid_0's l2: 0.153243\n",
      "[614]\tvalid_0's l2: 0.153237\n",
      "[615]\tvalid_0's l2: 0.153229\n",
      "[616]\tvalid_0's l2: 0.153233\n",
      "[617]\tvalid_0's l2: 0.153253\n",
      "[618]\tvalid_0's l2: 0.153259\n",
      "[619]\tvalid_0's l2: 0.15324\n",
      "[620]\tvalid_0's l2: 0.153257\n",
      "[621]\tvalid_0's l2: 0.15324\n",
      "[622]\tvalid_0's l2: 0.153231\n",
      "[623]\tvalid_0's l2: 0.153249\n",
      "[624]\tvalid_0's l2: 0.153255\n",
      "[625]\tvalid_0's l2: 0.153237\n",
      "[626]\tvalid_0's l2: 0.153258\n",
      "[627]\tvalid_0's l2: 0.153264\n",
      "[628]\tvalid_0's l2: 0.153256\n",
      "[629]\tvalid_0's l2: 0.153275\n",
      "[630]\tvalid_0's l2: 0.153258\n",
      "[631]\tvalid_0's l2: 0.153264\n",
      "[632]\tvalid_0's l2: 0.15326\n",
      "[633]\tvalid_0's l2: 0.153265\n",
      "[634]\tvalid_0's l2: 0.153273\n",
      "[635]\tvalid_0's l2: 0.153268\n",
      "[636]\tvalid_0's l2: 0.153269\n",
      "[637]\tvalid_0's l2: 0.153272\n",
      "[638]\tvalid_0's l2: 0.153288\n",
      "[639]\tvalid_0's l2: 0.153268\n",
      "[640]\tvalid_0's l2: 0.153287\n",
      "[641]\tvalid_0's l2: 0.153303\n",
      "[642]\tvalid_0's l2: 0.153293\n",
      "[643]\tvalid_0's l2: 0.153312\n",
      "[644]\tvalid_0's l2: 0.153305\n",
      "[645]\tvalid_0's l2: 0.153309\n",
      "[646]\tvalid_0's l2: 0.153302\n",
      "[647]\tvalid_0's l2: 0.153321\n",
      "[648]\tvalid_0's l2: 0.153338\n",
      "[649]\tvalid_0's l2: 0.153319\n",
      "[650]\tvalid_0's l2: 0.153322\n",
      "[651]\tvalid_0's l2: 0.153338\n",
      "[652]\tvalid_0's l2: 0.153343\n",
      "[653]\tvalid_0's l2: 0.153337\n",
      "[654]\tvalid_0's l2: 0.153335\n",
      "[655]\tvalid_0's l2: 0.153332\n",
      "[656]\tvalid_0's l2: 0.15333\n",
      "[657]\tvalid_0's l2: 0.153347\n",
      "[658]\tvalid_0's l2: 0.153352\n",
      "[659]\tvalid_0's l2: 0.153349\n",
      "[660]\tvalid_0's l2: 0.153367\n",
      "[661]\tvalid_0's l2: 0.153349\n",
      "[662]\tvalid_0's l2: 0.153367\n",
      "[663]\tvalid_0's l2: 0.153366\n",
      "[664]\tvalid_0's l2: 0.153366\n",
      "[665]\tvalid_0's l2: 0.153385\n",
      "[666]\tvalid_0's l2: 0.15338\n",
      "[667]\tvalid_0's l2: 0.153386\n",
      "[668]\tvalid_0's l2: 0.153388\n",
      "[669]\tvalid_0's l2: 0.153407\n",
      "[670]\tvalid_0's l2: 0.153389\n",
      "[671]\tvalid_0's l2: 0.153408\n",
      "[672]\tvalid_0's l2: 0.153391\n",
      "[673]\tvalid_0's l2: 0.153397\n",
      "[674]\tvalid_0's l2: 0.153416\n",
      "[675]\tvalid_0's l2: 0.153436\n",
      "[676]\tvalid_0's l2: 0.153416\n",
      "[677]\tvalid_0's l2: 0.153438\n",
      "[678]\tvalid_0's l2: 0.153434\n",
      "[679]\tvalid_0's l2: 0.153442\n",
      "[680]\tvalid_0's l2: 0.153442\n",
      "[681]\tvalid_0's l2: 0.153464\n",
      "[682]\tvalid_0's l2: 0.15346\n",
      "[683]\tvalid_0's l2: 0.153445\n",
      "[684]\tvalid_0's l2: 0.153466\n",
      "[685]\tvalid_0's l2: 0.153474\n",
      "[686]\tvalid_0's l2: 0.153476\n",
      "[687]\tvalid_0's l2: 0.153497\n",
      "[688]\tvalid_0's l2: 0.153484\n",
      "[689]\tvalid_0's l2: 0.153505\n",
      "[690]\tvalid_0's l2: 0.153528\n",
      "[691]\tvalid_0's l2: 0.153528\n",
      "[692]\tvalid_0's l2: 0.153513\n",
      "[693]\tvalid_0's l2: 0.153534\n",
      "[694]\tvalid_0's l2: 0.153512\n",
      "[695]\tvalid_0's l2: 0.153538\n",
      "[696]\tvalid_0's l2: 0.153535\n",
      "[697]\tvalid_0's l2: 0.153529\n",
      "[698]\tvalid_0's l2: 0.15355\n",
      "[699]\tvalid_0's l2: 0.153575\n",
      "[700]\tvalid_0's l2: 0.153576\n",
      "[701]\tvalid_0's l2: 0.153592\n",
      "[702]\tvalid_0's l2: 0.153618\n",
      "[703]\tvalid_0's l2: 0.153601\n",
      "[704]\tvalid_0's l2: 0.153623\n",
      "[705]\tvalid_0's l2: 0.153601\n",
      "[706]\tvalid_0's l2: 0.153603\n",
      "[707]\tvalid_0's l2: 0.153625\n",
      "[708]\tvalid_0's l2: 0.153625\n",
      "[709]\tvalid_0's l2: 0.153642\n",
      "[710]\tvalid_0's l2: 0.153653\n",
      "[711]\tvalid_0's l2: 0.153653\n",
      "[712]\tvalid_0's l2: 0.153655\n",
      "[713]\tvalid_0's l2: 0.153677\n",
      "[714]\tvalid_0's l2: 0.153693\n",
      "[715]\tvalid_0's l2: 0.153695\n",
      "[716]\tvalid_0's l2: 0.153718\n",
      "[717]\tvalid_0's l2: 0.153724\n",
      "[718]\tvalid_0's l2: 0.153748\n",
      "[719]\tvalid_0's l2: 0.153764\n",
      "[720]\tvalid_0's l2: 0.153792\n",
      "[721]\tvalid_0's l2: 0.153774\n",
      "[722]\tvalid_0's l2: 0.153797\n",
      "[723]\tvalid_0's l2: 0.153804\n",
      "[724]\tvalid_0's l2: 0.153806\n",
      "[725]\tvalid_0's l2: 0.153829\n",
      "[726]\tvalid_0's l2: 0.153856\n",
      "[727]\tvalid_0's l2: 0.15387\n",
      "[728]\tvalid_0's l2: 0.153869\n",
      "[729]\tvalid_0's l2: 0.1539\n",
      "[730]\tvalid_0's l2: 0.153906\n",
      "[731]\tvalid_0's l2: 0.153932\n",
      "[732]\tvalid_0's l2: 0.153945\n",
      "[733]\tvalid_0's l2: 0.153976\n",
      "[734]\tvalid_0's l2: 0.153975\n",
      "[735]\tvalid_0's l2: 0.153988\n",
      "[736]\tvalid_0's l2: 0.154002\n",
      "[737]\tvalid_0's l2: 0.154027\n",
      "[738]\tvalid_0's l2: 0.154034\n",
      "[739]\tvalid_0's l2: 0.154043\n",
      "[740]\tvalid_0's l2: 0.154066\n",
      "[741]\tvalid_0's l2: 0.154083\n",
      "[742]\tvalid_0's l2: 0.154111\n",
      "[743]\tvalid_0's l2: 0.154118\n",
      "[744]\tvalid_0's l2: 0.154126\n",
      "[745]\tvalid_0's l2: 0.154158\n",
      "[746]\tvalid_0's l2: 0.154148\n",
      "[747]\tvalid_0's l2: 0.154173\n",
      "[748]\tvalid_0's l2: 0.154187\n",
      "[749]\tvalid_0's l2: 0.154197\n",
      "[750]\tvalid_0's l2: 0.154222\n",
      "[751]\tvalid_0's l2: 0.154246\n",
      "[752]\tvalid_0's l2: 0.154265\n",
      "[753]\tvalid_0's l2: 0.154279\n",
      "[754]\tvalid_0's l2: 0.154282\n",
      "[755]\tvalid_0's l2: 0.15431\n",
      "[756]\tvalid_0's l2: 0.154335\n",
      "[757]\tvalid_0's l2: 0.154342\n",
      "[758]\tvalid_0's l2: 0.154368\n",
      "[759]\tvalid_0's l2: 0.154371\n",
      "[760]\tvalid_0's l2: 0.154385\n",
      "[761]\tvalid_0's l2: 0.154393\n",
      "[762]\tvalid_0's l2: 0.15442\n",
      "[763]\tvalid_0's l2: 0.154402\n",
      "[764]\tvalid_0's l2: 0.154424\n",
      "[765]\tvalid_0's l2: 0.15445\n",
      "[766]\tvalid_0's l2: 0.154439\n",
      "[767]\tvalid_0's l2: 0.154441\n",
      "[768]\tvalid_0's l2: 0.154466\n",
      "[769]\tvalid_0's l2: 0.154448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[770]\tvalid_0's l2: 0.154477\n",
      "[771]\tvalid_0's l2: 0.154489\n",
      "[772]\tvalid_0's l2: 0.154478\n",
      "[773]\tvalid_0's l2: 0.154486\n",
      "[774]\tvalid_0's l2: 0.154512\n",
      "[775]\tvalid_0's l2: 0.154506\n",
      "[776]\tvalid_0's l2: 0.154516\n",
      "[777]\tvalid_0's l2: 0.154545\n",
      "[778]\tvalid_0's l2: 0.154546\n",
      "[779]\tvalid_0's l2: 0.154559\n",
      "[780]\tvalid_0's l2: 0.154548\n",
      "[781]\tvalid_0's l2: 0.154576\n",
      "[782]\tvalid_0's l2: 0.154586\n",
      "[783]\tvalid_0's l2: 0.154588\n",
      "[784]\tvalid_0's l2: 0.154582\n",
      "[785]\tvalid_0's l2: 0.154609\n",
      "[786]\tvalid_0's l2: 0.154599\n",
      "[787]\tvalid_0's l2: 0.154613\n",
      "[788]\tvalid_0's l2: 0.154631\n",
      "[789]\tvalid_0's l2: 0.154636\n",
      "[790]\tvalid_0's l2: 0.154636\n",
      "[791]\tvalid_0's l2: 0.15465\n",
      "[792]\tvalid_0's l2: 0.154655\n",
      "[793]\tvalid_0's l2: 0.154682\n",
      "[794]\tvalid_0's l2: 0.154692\n",
      "[795]\tvalid_0's l2: 0.154695\n",
      "[796]\tvalid_0's l2: 0.15469\n",
      "[797]\tvalid_0's l2: 0.15472\n",
      "[798]\tvalid_0's l2: 0.154707\n",
      "[799]\tvalid_0's l2: 0.154736\n",
      "[800]\tvalid_0's l2: 0.15473\n",
      "[801]\tvalid_0's l2: 0.154759\n",
      "[802]\tvalid_0's l2: 0.154773\n",
      "[803]\tvalid_0's l2: 0.154794\n",
      "[804]\tvalid_0's l2: 0.154788\n",
      "[805]\tvalid_0's l2: 0.15482\n",
      "[806]\tvalid_0's l2: 0.154823\n",
      "[807]\tvalid_0's l2: 0.154839\n",
      "[808]\tvalid_0's l2: 0.154833\n",
      "[809]\tvalid_0's l2: 0.154866\n",
      "[810]\tvalid_0's l2: 0.154862\n",
      "[811]\tvalid_0's l2: 0.154889\n",
      "[812]\tvalid_0's l2: 0.154877\n",
      "[813]\tvalid_0's l2: 0.154909\n",
      "[814]\tvalid_0's l2: 0.154913\n",
      "[815]\tvalid_0's l2: 0.154935\n",
      "[816]\tvalid_0's l2: 0.15493\n",
      "[817]\tvalid_0's l2: 0.154963\n",
      "[818]\tvalid_0's l2: 0.154989\n",
      "[819]\tvalid_0's l2: 0.155\n",
      "[820]\tvalid_0's l2: 0.155005\n",
      "[821]\tvalid_0's l2: 0.155025\n",
      "[822]\tvalid_0's l2: 0.155033\n",
      "[823]\tvalid_0's l2: 0.155043\n",
      "[824]\tvalid_0's l2: 0.155038\n",
      "[825]\tvalid_0's l2: 0.155052\n",
      "[826]\tvalid_0's l2: 0.155058\n",
      "[827]\tvalid_0's l2: 0.155068\n",
      "[828]\tvalid_0's l2: 0.155054\n",
      "[829]\tvalid_0's l2: 0.15508\n",
      "[830]\tvalid_0's l2: 0.155085\n",
      "[831]\tvalid_0's l2: 0.155098\n",
      "[832]\tvalid_0's l2: 0.155111\n",
      "[833]\tvalid_0's l2: 0.155116\n",
      "[834]\tvalid_0's l2: 0.15514\n",
      "[835]\tvalid_0's l2: 0.155126\n",
      "[836]\tvalid_0's l2: 0.155149\n",
      "[837]\tvalid_0's l2: 0.155157\n",
      "[838]\tvalid_0's l2: 0.155168\n",
      "[839]\tvalid_0's l2: 0.155163\n",
      "[840]\tvalid_0's l2: 0.155178\n",
      "[841]\tvalid_0's l2: 0.155202\n",
      "[842]\tvalid_0's l2: 0.155213\n",
      "[843]\tvalid_0's l2: 0.155199\n",
      "[844]\tvalid_0's l2: 0.155223\n",
      "[845]\tvalid_0's l2: 0.15522\n",
      "[846]\tvalid_0's l2: 0.155233\n",
      "[847]\tvalid_0's l2: 0.155241\n",
      "[848]\tvalid_0's l2: 0.155252\n",
      "[849]\tvalid_0's l2: 0.155261\n",
      "[850]\tvalid_0's l2: 0.155272\n",
      "[851]\tvalid_0's l2: 0.155267\n",
      "[852]\tvalid_0's l2: 0.155283\n",
      "[853]\tvalid_0's l2: 0.155305\n",
      "[854]\tvalid_0's l2: 0.155311\n",
      "[855]\tvalid_0's l2: 0.155315\n",
      "[856]\tvalid_0's l2: 0.155321\n",
      "[857]\tvalid_0's l2: 0.155335\n",
      "[858]\tvalid_0's l2: 0.155343\n",
      "[859]\tvalid_0's l2: 0.155368\n",
      "[860]\tvalid_0's l2: 0.155381\n",
      "[861]\tvalid_0's l2: 0.155397\n",
      "[862]\tvalid_0's l2: 0.15539\n",
      "[863]\tvalid_0's l2: 0.155417\n",
      "[864]\tvalid_0's l2: 0.15541\n",
      "[865]\tvalid_0's l2: 0.155426\n",
      "[866]\tvalid_0's l2: 0.155413\n",
      "[867]\tvalid_0's l2: 0.155441\n",
      "[868]\tvalid_0's l2: 0.155447\n",
      "[869]\tvalid_0's l2: 0.155462\n",
      "[870]\tvalid_0's l2: 0.155468\n",
      "[871]\tvalid_0's l2: 0.155496\n",
      "[872]\tvalid_0's l2: 0.15549\n",
      "[873]\tvalid_0's l2: 0.155507\n",
      "[874]\tvalid_0's l2: 0.15552\n",
      "[875]\tvalid_0's l2: 0.155527\n",
      "[876]\tvalid_0's l2: 0.155552\n",
      "[877]\tvalid_0's l2: 0.15555\n",
      "[878]\tvalid_0's l2: 0.155557\n",
      "[879]\tvalid_0's l2: 0.155563\n",
      "[880]\tvalid_0's l2: 0.155591\n",
      "[881]\tvalid_0's l2: 0.155602\n",
      "[882]\tvalid_0's l2: 0.15562\n",
      "[883]\tvalid_0's l2: 0.155613\n",
      "[884]\tvalid_0's l2: 0.155631\n",
      "[885]\tvalid_0's l2: 0.155639\n",
      "[886]\tvalid_0's l2: 0.155653\n",
      "[887]\tvalid_0's l2: 0.155648\n",
      "[888]\tvalid_0's l2: 0.155677\n",
      "[889]\tvalid_0's l2: 0.155683\n",
      "[890]\tvalid_0's l2: 0.15569\n",
      "[891]\tvalid_0's l2: 0.155696\n",
      "[892]\tvalid_0's l2: 0.155711\n",
      "[893]\tvalid_0's l2: 0.155726\n",
      "[894]\tvalid_0's l2: 0.15572\n",
      "[895]\tvalid_0's l2: 0.155748\n",
      "[896]\tvalid_0's l2: 0.155742\n",
      "[897]\tvalid_0's l2: 0.155758\n",
      "[898]\tvalid_0's l2: 0.155753\n",
      "[899]\tvalid_0's l2: 0.15578\n",
      "[900]\tvalid_0's l2: 0.155786\n",
      "[901]\tvalid_0's l2: 0.155812\n",
      "[902]\tvalid_0's l2: 0.155825\n",
      "[903]\tvalid_0's l2: 0.155843\n",
      "[904]\tvalid_0's l2: 0.155837\n",
      "[905]\tvalid_0's l2: 0.155866\n",
      "[906]\tvalid_0's l2: 0.15586\n",
      "[907]\tvalid_0's l2: 0.155876\n",
      "[908]\tvalid_0's l2: 0.155871\n",
      "[909]\tvalid_0's l2: 0.155899\n",
      "[910]\tvalid_0's l2: 0.155905\n",
      "[911]\tvalid_0's l2: 0.155913\n",
      "[912]\tvalid_0's l2: 0.155919\n",
      "[913]\tvalid_0's l2: 0.155949\n",
      "[914]\tvalid_0's l2: 0.155962\n",
      "[915]\tvalid_0's l2: 0.155958\n",
      "[916]\tvalid_0's l2: 0.155974\n",
      "[917]\tvalid_0's l2: 0.15598\n",
      "[918]\tvalid_0's l2: 0.155997\n",
      "[919]\tvalid_0's l2: 0.156006\n",
      "[920]\tvalid_0's l2: 0.15602\n",
      "[921]\tvalid_0's l2: 0.156037\n",
      "[922]\tvalid_0's l2: 0.156053\n",
      "[923]\tvalid_0's l2: 0.15605\n",
      "[924]\tvalid_0's l2: 0.156079\n",
      "[925]\tvalid_0's l2: 0.156086\n",
      "[926]\tvalid_0's l2: 0.156101\n",
      "[927]\tvalid_0's l2: 0.156096\n",
      "[928]\tvalid_0's l2: 0.156104\n",
      "[929]\tvalid_0's l2: 0.156098\n",
      "[930]\tvalid_0's l2: 0.156128\n",
      "[931]\tvalid_0's l2: 0.156135\n",
      "[932]\tvalid_0's l2: 0.156151\n",
      "[933]\tvalid_0's l2: 0.156147\n",
      "[934]\tvalid_0's l2: 0.156177\n",
      "[935]\tvalid_0's l2: 0.156202\n",
      "[936]\tvalid_0's l2: 0.156198\n",
      "[937]\tvalid_0's l2: 0.156214\n",
      "[938]\tvalid_0's l2: 0.15621\n",
      "[939]\tvalid_0's l2: 0.156229\n",
      "[940]\tvalid_0's l2: 0.156224\n",
      "[941]\tvalid_0's l2: 0.156252\n",
      "[942]\tvalid_0's l2: 0.156265\n",
      "[943]\tvalid_0's l2: 0.156293\n",
      "[944]\tvalid_0's l2: 0.156287\n",
      "[945]\tvalid_0's l2: 0.156305\n",
      "[946]\tvalid_0's l2: 0.156313\n",
      "[947]\tvalid_0's l2: 0.15634\n",
      "[948]\tvalid_0's l2: 0.156336\n",
      "[949]\tvalid_0's l2: 0.156366\n",
      "[950]\tvalid_0's l2: 0.156362\n",
      "[951]\tvalid_0's l2: 0.156378\n",
      "[952]\tvalid_0's l2: 0.156372\n",
      "[953]\tvalid_0's l2: 0.156392\n",
      "[954]\tvalid_0's l2: 0.1564\n",
      "[955]\tvalid_0's l2: 0.156416\n",
      "[956]\tvalid_0's l2: 0.156431\n",
      "[957]\tvalid_0's l2: 0.15644\n",
      "[958]\tvalid_0's l2: 0.156457\n",
      "[959]\tvalid_0's l2: 0.156466\n",
      "[960]\tvalid_0's l2: 0.156493\n",
      "[961]\tvalid_0's l2: 0.156501\n",
      "[962]\tvalid_0's l2: 0.156517\n",
      "[963]\tvalid_0's l2: 0.156531\n",
      "[964]\tvalid_0's l2: 0.156548\n",
      "[965]\tvalid_0's l2: 0.156555\n",
      "[966]\tvalid_0's l2: 0.156571\n",
      "[967]\tvalid_0's l2: 0.156567\n",
      "[968]\tvalid_0's l2: 0.156597\n",
      "[969]\tvalid_0's l2: 0.156603\n",
      "[970]\tvalid_0's l2: 0.156618\n",
      "[971]\tvalid_0's l2: 0.156636\n",
      "[972]\tvalid_0's l2: 0.156644\n",
      "[973]\tvalid_0's l2: 0.156661\n",
      "[974]\tvalid_0's l2: 0.156658\n",
      "[975]\tvalid_0's l2: 0.156687\n",
      "[976]\tvalid_0's l2: 0.156683\n",
      "[977]\tvalid_0's l2: 0.1567\n",
      "[978]\tvalid_0's l2: 0.156708\n",
      "[979]\tvalid_0's l2: 0.156725\n",
      "[980]\tvalid_0's l2: 0.156732\n",
      "[981]\tvalid_0's l2: 0.156748\n",
      "[982]\tvalid_0's l2: 0.156757\n",
      "[983]\tvalid_0's l2: 0.156775\n",
      "[984]\tvalid_0's l2: 0.156789\n",
      "[985]\tvalid_0's l2: 0.156799\n",
      "[986]\tvalid_0's l2: 0.156817\n",
      "[987]\tvalid_0's l2: 0.156813\n",
      "[988]\tvalid_0's l2: 0.156841\n",
      "[989]\tvalid_0's l2: 0.156837\n",
      "[990]\tvalid_0's l2: 0.156867\n",
      "[991]\tvalid_0's l2: 0.156881\n",
      "[992]\tvalid_0's l2: 0.156899\n",
      "[993]\tvalid_0's l2: 0.156908\n",
      "[994]\tvalid_0's l2: 0.156936\n",
      "[995]\tvalid_0's l2: 0.156933\n",
      "[996]\tvalid_0's l2: 0.156951\n",
      "[997]\tvalid_0's l2: 0.156959\n",
      "[998]\tvalid_0's l2: 0.156976\n",
      "[999]\tvalid_0's l2: 0.156973\n",
      "[1000]\tvalid_0's l2: 0.157002\n",
      "[1001]\tvalid_0's l2: 0.157012\n",
      "[1002]\tvalid_0's l2: 0.157029\n",
      "[1003]\tvalid_0's l2: 0.157026\n",
      "[1004]\tvalid_0's l2: 0.157043\n",
      "[1005]\tvalid_0's l2: 0.157069\n",
      "[1006]\tvalid_0's l2: 0.157066\n",
      "[1007]\tvalid_0's l2: 0.157095\n",
      "[1008]\tvalid_0's l2: 0.157093\n",
      "[1009]\tvalid_0's l2: 0.157108\n",
      "[1010]\tvalid_0's l2: 0.157116\n",
      "[1011]\tvalid_0's l2: 0.157134\n",
      "[1012]\tvalid_0's l2: 0.157161\n",
      "[1013]\tvalid_0's l2: 0.157178\n",
      "[1014]\tvalid_0's l2: 0.157199\n",
      "[1015]\tvalid_0's l2: 0.15722\n",
      "[1016]\tvalid_0's l2: 0.157242\n",
      "[1017]\tvalid_0's l2: 0.157263\n",
      "[1018]\tvalid_0's l2: 0.157284\n",
      "[1019]\tvalid_0's l2: 0.157305\n",
      "[1020]\tvalid_0's l2: 0.157326\n",
      "[1021]\tvalid_0's l2: 0.157348\n",
      "[1022]\tvalid_0's l2: 0.157361\n",
      "[1023]\tvalid_0's l2: 0.157383\n",
      "[1024]\tvalid_0's l2: 0.157405\n",
      "[1025]\tvalid_0's l2: 0.157426\n",
      "[1026]\tvalid_0's l2: 0.157448\n",
      "[1027]\tvalid_0's l2: 0.157469\n",
      "[1028]\tvalid_0's l2: 0.157491\n",
      "[1029]\tvalid_0's l2: 0.157512\n",
      "[1030]\tvalid_0's l2: 0.157525\n",
      "[1031]\tvalid_0's l2: 0.157547\n",
      "[1032]\tvalid_0's l2: 0.157569\n",
      "[1033]\tvalid_0's l2: 0.15759\n",
      "[1034]\tvalid_0's l2: 0.157612\n",
      "[1035]\tvalid_0's l2: 0.157621\n",
      "[1036]\tvalid_0's l2: 0.157643\n",
      "[1037]\tvalid_0's l2: 0.157653\n",
      "[1038]\tvalid_0's l2: 0.157674\n",
      "[1039]\tvalid_0's l2: 0.157666\n",
      "[1040]\tvalid_0's l2: 0.157676\n",
      "[1041]\tvalid_0's l2: 0.157698\n",
      "[1042]\tvalid_0's l2: 0.157707\n",
      "[1043]\tvalid_0's l2: 0.157699\n",
      "[1044]\tvalid_0's l2: 0.157722\n",
      "[1045]\tvalid_0's l2: 0.157731\n",
      "[1046]\tvalid_0's l2: 0.157723\n",
      "[1047]\tvalid_0's l2: 0.157745\n",
      "[1048]\tvalid_0's l2: 0.157755\n",
      "[1049]\tvalid_0's l2: 0.157747\n",
      "[1050]\tvalid_0's l2: 0.15777\n",
      "[1051]\tvalid_0's l2: 0.157779\n",
      "[1052]\tvalid_0's l2: 0.157789\n",
      "[1053]\tvalid_0's l2: 0.157811\n",
      "[1054]\tvalid_0's l2: 0.157804\n",
      "[1055]\tvalid_0's l2: 0.157813\n",
      "[1056]\tvalid_0's l2: 0.157836\n",
      "[1057]\tvalid_0's l2: 0.157828\n",
      "[1058]\tvalid_0's l2: 0.157838\n",
      "[1059]\tvalid_0's l2: 0.157861\n",
      "[1060]\tvalid_0's l2: 0.157853\n",
      "[1061]\tvalid_0's l2: 0.157863\n",
      "[1062]\tvalid_0's l2: 0.157886\n",
      "[1063]\tvalid_0's l2: 0.157896\n",
      "[1064]\tvalid_0's l2: 0.157889\n",
      "[1065]\tvalid_0's l2: 0.157912\n",
      "[1066]\tvalid_0's l2: 0.157922\n",
      "[1067]\tvalid_0's l2: 0.157914\n",
      "[1068]\tvalid_0's l2: 0.157938\n",
      "[1069]\tvalid_0's l2: 0.157948\n",
      "[1070]\tvalid_0's l2: 0.157941\n",
      "[1071]\tvalid_0's l2: 0.157964\n",
      "[1072]\tvalid_0's l2: 0.157974\n",
      "[1073]\tvalid_0's l2: 0.157967\n",
      "[1074]\tvalid_0's l2: 0.157977\n",
      "[1075]\tvalid_0's l2: 0.158\n",
      "[1076]\tvalid_0's l2: 0.15801\n",
      "[1077]\tvalid_0's l2: 0.158034\n",
      "[1078]\tvalid_0's l2: 0.158027\n",
      "[1079]\tvalid_0's l2: 0.158037\n",
      "[1080]\tvalid_0's l2: 0.15806\n",
      "[1081]\tvalid_0's l2: 0.158054\n",
      "[1082]\tvalid_0's l2: 0.158064\n",
      "[1083]\tvalid_0's l2: 0.158088\n",
      "[1084]\tvalid_0's l2: 0.158081\n",
      "[1085]\tvalid_0's l2: 0.158092\n",
      "[1086]\tvalid_0's l2: 0.158085\n",
      "[1087]\tvalid_0's l2: 0.158109\n",
      "[1088]\tvalid_0's l2: 0.158119\n",
      "[1089]\tvalid_0's l2: 0.15813\n",
      "[1090]\tvalid_0's l2: 0.158153\n",
      "[1091]\tvalid_0's l2: 0.158147\n",
      "[1092]\tvalid_0's l2: 0.158158\n",
      "[1093]\tvalid_0's l2: 0.158181\n",
      "[1094]\tvalid_0's l2: 0.158175\n",
      "[1095]\tvalid_0's l2: 0.158186\n",
      "[1096]\tvalid_0's l2: 0.15821\n",
      "[1097]\tvalid_0's l2: 0.158204\n",
      "[1098]\tvalid_0's l2: 0.158214\n",
      "[1099]\tvalid_0's l2: 0.158243\n",
      "[1100]\tvalid_0's l2: 0.158271\n",
      "[1101]\tvalid_0's l2: 0.158295\n",
      "[1102]\tvalid_0's l2: 0.158323\n",
      "[1103]\tvalid_0's l2: 0.158352\n",
      "[1104]\tvalid_0's l2: 0.15838\n",
      "[1105]\tvalid_0's l2: 0.158409\n",
      "[1106]\tvalid_0's l2: 0.158433\n",
      "[1107]\tvalid_0's l2: 0.158461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1108]\tvalid_0's l2: 0.15849\n",
      "[1109]\tvalid_0's l2: 0.158519\n",
      "[1110]\tvalid_0's l2: 0.158547\n",
      "[1111]\tvalid_0's l2: 0.158579\n",
      "[1112]\tvalid_0's l2: 0.158608\n",
      "[1113]\tvalid_0's l2: 0.158637\n",
      "[1114]\tvalid_0's l2: 0.158669\n",
      "[1115]\tvalid_0's l2: 0.158698\n",
      "[1116]\tvalid_0's l2: 0.158727\n",
      "[1117]\tvalid_0's l2: 0.158759\n",
      "[1118]\tvalid_0's l2: 0.158788\n",
      "[1119]\tvalid_0's l2: 0.15882\n",
      "[1120]\tvalid_0's l2: 0.158849\n",
      "[1121]\tvalid_0's l2: 0.158881\n",
      "[1122]\tvalid_0's l2: 0.15891\n",
      "[1123]\tvalid_0's l2: 0.158939\n",
      "[1124]\tvalid_0's l2: 0.158957\n",
      "[1125]\tvalid_0's l2: 0.158987\n",
      "[1126]\tvalid_0's l2: 0.159016\n",
      "[1127]\tvalid_0's l2: 0.159045\n",
      "[1128]\tvalid_0's l2: 0.159063\n",
      "[1129]\tvalid_0's l2: 0.159092\n",
      "[1130]\tvalid_0's l2: 0.159122\n",
      "[1131]\tvalid_0's l2: 0.159151\n",
      "[1132]\tvalid_0's l2: 0.15917\n",
      "[1133]\tvalid_0's l2: 0.159199\n",
      "[1134]\tvalid_0's l2: 0.159217\n",
      "[1135]\tvalid_0's l2: 0.159246\n",
      "[1136]\tvalid_0's l2: 0.159277\n",
      "[1137]\tvalid_0's l2: 0.159306\n",
      "[1138]\tvalid_0's l2: 0.159324\n",
      "[1139]\tvalid_0's l2: 0.159353\n",
      "[1140]\tvalid_0's l2: 0.159382\n",
      "[1141]\tvalid_0's l2: 0.159412\n",
      "[1142]\tvalid_0's l2: 0.159429\n",
      "[1143]\tvalid_0's l2: 0.159458\n",
      "[1144]\tvalid_0's l2: 0.159487\n",
      "[1145]\tvalid_0's l2: 0.159503\n",
      "[1146]\tvalid_0's l2: 0.159532\n",
      "[1147]\tvalid_0's l2: 0.159561\n",
      "[1148]\tvalid_0's l2: 0.159577\n",
      "[1149]\tvalid_0's l2: 0.159606\n",
      "[1150]\tvalid_0's l2: 0.159635\n",
      "[1151]\tvalid_0's l2: 0.159651\n",
      "[1152]\tvalid_0's l2: 0.15968\n",
      "[1153]\tvalid_0's l2: 0.159709\n",
      "[1154]\tvalid_0's l2: 0.15974\n",
      "[1155]\tvalid_0's l2: 0.159756\n",
      "[1156]\tvalid_0's l2: 0.159785\n",
      "[1157]\tvalid_0's l2: 0.159814\n",
      "[1158]\tvalid_0's l2: 0.15983\n",
      "[1159]\tvalid_0's l2: 0.159859\n",
      "[1160]\tvalid_0's l2: 0.159875\n",
      "[1161]\tvalid_0's l2: 0.159895\n",
      "[1162]\tvalid_0's l2: 0.159915\n",
      "[1163]\tvalid_0's l2: 0.159945\n",
      "[1164]\tvalid_0's l2: 0.159966\n",
      "[1165]\tvalid_0's l2: 0.159986\n",
      "[1166]\tvalid_0's l2: 0.160016\n",
      "[1167]\tvalid_0's l2: 0.160037\n",
      "[1168]\tvalid_0's l2: 0.160067\n",
      "[1169]\tvalid_0's l2: 0.160088\n",
      "[1170]\tvalid_0's l2: 0.160118\n",
      "[1171]\tvalid_0's l2: 0.160139\n",
      "[1172]\tvalid_0's l2: 0.160159\n",
      "[1173]\tvalid_0's l2: 0.16019\n",
      "[1174]\tvalid_0's l2: 0.16021\n",
      "[1175]\tvalid_0's l2: 0.160233\n",
      "[1176]\tvalid_0's l2: 0.160254\n",
      "[1177]\tvalid_0's l2: 0.160274\n",
      "[1178]\tvalid_0's l2: 0.160305\n",
      "[1179]\tvalid_0's l2: 0.160325\n",
      "[1180]\tvalid_0's l2: 0.160349\n",
      "[1181]\tvalid_0's l2: 0.160369\n",
      "[1182]\tvalid_0's l2: 0.1604\n",
      "[1183]\tvalid_0's l2: 0.160415\n",
      "[1184]\tvalid_0's l2: 0.160435\n",
      "[1185]\tvalid_0's l2: 0.160458\n",
      "[1186]\tvalid_0's l2: 0.160469\n",
      "[1187]\tvalid_0's l2: 0.160484\n",
      "[1188]\tvalid_0's l2: 0.160499\n",
      "[1189]\tvalid_0's l2: 0.16053\n",
      "[1190]\tvalid_0's l2: 0.160544\n",
      "[1191]\tvalid_0's l2: 0.160568\n",
      "[1192]\tvalid_0's l2: 0.160582\n",
      "[1193]\tvalid_0's l2: 0.160603\n",
      "[1194]\tvalid_0's l2: 0.160632\n",
      "[1195]\tvalid_0's l2: 0.160643\n",
      "[1196]\tvalid_0's l2: 0.160656\n",
      "[1197]\tvalid_0's l2: 0.16067\n",
      "[1198]\tvalid_0's l2: 0.160699\n",
      "[1199]\tvalid_0's l2: 0.160712\n",
      "[1200]\tvalid_0's l2: 0.160733\n",
      "[1201]\tvalid_0's l2: 0.160746\n",
      "[1202]\tvalid_0's l2: 0.160775\n",
      "[1203]\tvalid_0's l2: 0.160786\n",
      "[1204]\tvalid_0's l2: 0.160798\n",
      "[1205]\tvalid_0's l2: 0.160813\n",
      "[1206]\tvalid_0's l2: 0.160843\n",
      "[1207]\tvalid_0's l2: 0.160855\n",
      "[1208]\tvalid_0's l2: 0.160876\n",
      "[1209]\tvalid_0's l2: 0.160889\n",
      "[1210]\tvalid_0's l2: 0.160918\n",
      "[1211]\tvalid_0's l2: 0.160931\n",
      "[1212]\tvalid_0's l2: 0.160962\n",
      "[1213]\tvalid_0's l2: 0.160975\n",
      "[1214]\tvalid_0's l2: 0.160993\n",
      "[1215]\tvalid_0's l2: 0.161022\n",
      "[1216]\tvalid_0's l2: 0.161034\n",
      "[1217]\tvalid_0's l2: 0.161063\n",
      "[1218]\tvalid_0's l2: 0.161081\n",
      "[1219]\tvalid_0's l2: 0.161111\n",
      "[1220]\tvalid_0's l2: 0.161123\n",
      "[1221]\tvalid_0's l2: 0.161152\n",
      "[1222]\tvalid_0's l2: 0.161165\n",
      "[1223]\tvalid_0's l2: 0.161178\n",
      "[1224]\tvalid_0's l2: 0.161193\n",
      "[1225]\tvalid_0's l2: 0.161225\n",
      "[1226]\tvalid_0's l2: 0.161241\n",
      "[1227]\tvalid_0's l2: 0.16127\n",
      "[1228]\tvalid_0's l2: 0.161275\n",
      "[1229]\tvalid_0's l2: 0.16129\n",
      "[1230]\tvalid_0's l2: 0.16132\n",
      "[1231]\tvalid_0's l2: 0.161325\n",
      "[1232]\tvalid_0's l2: 0.161353\n",
      "[1233]\tvalid_0's l2: 0.161371\n",
      "[1234]\tvalid_0's l2: 0.161386\n",
      "[1235]\tvalid_0's l2: 0.161415\n",
      "[1236]\tvalid_0's l2: 0.161421\n",
      "[1237]\tvalid_0's l2: 0.161452\n",
      "[1238]\tvalid_0's l2: 0.161469\n",
      "[1239]\tvalid_0's l2: 0.161472\n",
      "[1240]\tvalid_0's l2: 0.161488\n",
      "[1241]\tvalid_0's l2: 0.161517\n",
      "[1242]\tvalid_0's l2: 0.161522\n",
      "[1243]\tvalid_0's l2: 0.161547\n",
      "[1244]\tvalid_0's l2: 0.16156\n",
      "[1245]\tvalid_0's l2: 0.161576\n",
      "[1246]\tvalid_0's l2: 0.161607\n",
      "[1247]\tvalid_0's l2: 0.161612\n",
      "[1248]\tvalid_0's l2: 0.161629\n",
      "[1249]\tvalid_0's l2: 0.161658\n",
      "[1250]\tvalid_0's l2: 0.161659\n",
      "[1251]\tvalid_0's l2: 0.161674\n",
      "[1252]\tvalid_0's l2: 0.161703\n",
      "[1253]\tvalid_0's l2: 0.161705\n",
      "[1254]\tvalid_0's l2: 0.161721\n",
      "[1255]\tvalid_0's l2: 0.161752\n",
      "[1256]\tvalid_0's l2: 0.161753\n",
      "[1257]\tvalid_0's l2: 0.161771\n",
      "[1258]\tvalid_0's l2: 0.161796\n",
      "[1259]\tvalid_0's l2: 0.161814\n",
      "[1260]\tvalid_0's l2: 0.16183\n",
      "[1261]\tvalid_0's l2: 0.161859\n",
      "[1262]\tvalid_0's l2: 0.161861\n",
      "[1263]\tvalid_0's l2: 0.161865\n",
      "[1264]\tvalid_0's l2: 0.161892\n",
      "[1265]\tvalid_0's l2: 0.161905\n",
      "[1266]\tvalid_0's l2: 0.161934\n",
      "[1267]\tvalid_0's l2: 0.161938\n",
      "[1268]\tvalid_0's l2: 0.161957\n",
      "[1269]\tvalid_0's l2: 0.161975\n",
      "[1270]\tvalid_0's l2: 0.162004\n",
      "[1271]\tvalid_0's l2: 0.162022\n",
      "[1272]\tvalid_0's l2: 0.16204\n",
      "[1273]\tvalid_0's l2: 0.162069\n",
      "[1274]\tvalid_0's l2: 0.162086\n",
      "[1275]\tvalid_0's l2: 0.162104\n",
      "[1276]\tvalid_0's l2: 0.162135\n",
      "[1277]\tvalid_0's l2: 0.162153\n",
      "[1278]\tvalid_0's l2: 0.162171\n",
      "[1279]\tvalid_0's l2: 0.162201\n",
      "[1280]\tvalid_0's l2: 0.162217\n",
      "[1281]\tvalid_0's l2: 0.162229\n",
      "[1282]\tvalid_0's l2: 0.162258\n",
      "[1283]\tvalid_0's l2: 0.162271\n",
      "[1284]\tvalid_0's l2: 0.1623\n",
      "[1285]\tvalid_0's l2: 0.162306\n",
      "[1286]\tvalid_0's l2: 0.162324\n",
      "[1287]\tvalid_0's l2: 0.162354\n",
      "[1288]\tvalid_0's l2: 0.162366\n",
      "[1289]\tvalid_0's l2: 0.162397\n",
      "[1290]\tvalid_0's l2: 0.162415\n",
      "[1291]\tvalid_0's l2: 0.162433\n",
      "[1292]\tvalid_0's l2: 0.162462\n",
      "[1293]\tvalid_0's l2: 0.162468\n",
      "[1294]\tvalid_0's l2: 0.162486\n",
      "[1295]\tvalid_0's l2: 0.162515\n",
      "[1296]\tvalid_0's l2: 0.162533\n",
      "[1297]\tvalid_0's l2: 0.162562\n",
      "[1298]\tvalid_0's l2: 0.16258\n",
      "[1299]\tvalid_0's l2: 0.162586\n",
      "[1300]\tvalid_0's l2: 0.162618\n",
      "[1301]\tvalid_0's l2: 0.162635\n",
      "[1302]\tvalid_0's l2: 0.162653\n",
      "[1303]\tvalid_0's l2: 0.162682\n",
      "[1304]\tvalid_0's l2: 0.162689\n",
      "[1305]\tvalid_0's l2: 0.162695\n",
      "[1306]\tvalid_0's l2: 0.162725\n",
      "[1307]\tvalid_0's l2: 0.162742\n",
      "[1308]\tvalid_0's l2: 0.162759\n",
      "[1309]\tvalid_0's l2: 0.16279\n",
      "[1310]\tvalid_0's l2: 0.162797\n",
      "[1311]\tvalid_0's l2: 0.162814\n",
      "[1312]\tvalid_0's l2: 0.162838\n",
      "[1313]\tvalid_0's l2: 0.162856\n",
      "[1314]\tvalid_0's l2: 0.162874\n",
      "[1315]\tvalid_0's l2: 0.16289\n",
      "[1316]\tvalid_0's l2: 0.16292\n",
      "[1317]\tvalid_0's l2: 0.162938\n",
      "[1318]\tvalid_0's l2: 0.162955\n",
      "[1319]\tvalid_0's l2: 0.162965\n",
      "[1320]\tvalid_0's l2: 0.162982\n",
      "[1321]\tvalid_0's l2: 0.162999\n",
      "[1322]\tvalid_0's l2: 0.163016\n",
      "[1323]\tvalid_0's l2: 0.163046\n",
      "[1324]\tvalid_0's l2: 0.163063\n",
      "[1325]\tvalid_0's l2: 0.163092\n",
      "[1326]\tvalid_0's l2: 0.16311\n",
      "[1327]\tvalid_0's l2: 0.163128\n",
      "[1328]\tvalid_0's l2: 0.163146\n",
      "[1329]\tvalid_0's l2: 0.163163\n",
      "[1330]\tvalid_0's l2: 0.163172\n",
      "[1331]\tvalid_0's l2: 0.163189\n",
      "[1332]\tvalid_0's l2: 0.163206\n",
      "[1333]\tvalid_0's l2: 0.163223\n",
      "[1334]\tvalid_0's l2: 0.163232\n",
      "[1335]\tvalid_0's l2: 0.16325\n",
      "[1336]\tvalid_0's l2: 0.16327\n",
      "[1337]\tvalid_0's l2: 0.163287\n",
      "[1338]\tvalid_0's l2: 0.163304\n",
      "[1339]\tvalid_0's l2: 0.163317\n",
      "[1340]\tvalid_0's l2: 0.163333\n",
      "[1341]\tvalid_0's l2: 0.163351\n",
      "[1342]\tvalid_0's l2: 0.163367\n",
      "[1343]\tvalid_0's l2: 0.163385\n",
      "[1344]\tvalid_0's l2: 0.163404\n",
      "[1345]\tvalid_0's l2: 0.163417\n",
      "[1346]\tvalid_0's l2: 0.163434\n",
      "[1347]\tvalid_0's l2: 0.163453\n",
      "[1348]\tvalid_0's l2: 0.163469\n",
      "[1349]\tvalid_0's l2: 0.163487\n",
      "[1350]\tvalid_0's l2: 0.163504\n",
      "[1351]\tvalid_0's l2: 0.163533\n",
      "[1352]\tvalid_0's l2: 0.163549\n",
      "[1353]\tvalid_0's l2: 0.163579\n",
      "[1354]\tvalid_0's l2: 0.163591\n",
      "[1355]\tvalid_0's l2: 0.163609\n",
      "[1356]\tvalid_0's l2: 0.163625\n",
      "[1357]\tvalid_0's l2: 0.163644\n",
      "[1358]\tvalid_0's l2: 0.163661\n",
      "[1359]\tvalid_0's l2: 0.163677\n",
      "[1360]\tvalid_0's l2: 0.163694\n",
      "[1361]\tvalid_0's l2: 0.163712\n",
      "[1362]\tvalid_0's l2: 0.163728\n",
      "[1363]\tvalid_0's l2: 0.163757\n",
      "[1364]\tvalid_0's l2: 0.163773\n",
      "[1365]\tvalid_0's l2: 0.163786\n",
      "[1366]\tvalid_0's l2: 0.163803\n",
      "[1367]\tvalid_0's l2: 0.163819\n",
      "[1368]\tvalid_0's l2: 0.163837\n",
      "[1369]\tvalid_0's l2: 0.163853\n",
      "[1370]\tvalid_0's l2: 0.163875\n",
      "[1371]\tvalid_0's l2: 0.163891\n",
      "[1372]\tvalid_0's l2: 0.163914\n",
      "[1373]\tvalid_0's l2: 0.163931\n",
      "[1374]\tvalid_0's l2: 0.163948\n",
      "[1375]\tvalid_0's l2: 0.163966\n",
      "[1376]\tvalid_0's l2: 0.163981\n",
      "[1377]\tvalid_0's l2: 0.163997\n",
      "[1378]\tvalid_0's l2: 0.16402\n",
      "[1379]\tvalid_0's l2: 0.164036\n",
      "[1380]\tvalid_0's l2: 0.164053\n",
      "[1381]\tvalid_0's l2: 0.164069\n",
      "[1382]\tvalid_0's l2: 0.164086\n",
      "[1383]\tvalid_0's l2: 0.164102\n",
      "[1384]\tvalid_0's l2: 0.164125\n",
      "[1385]\tvalid_0's l2: 0.164137\n",
      "[1386]\tvalid_0's l2: 0.164153\n",
      "[1387]\tvalid_0's l2: 0.16417\n",
      "[1388]\tvalid_0's l2: 0.164187\n",
      "[1389]\tvalid_0's l2: 0.164203\n",
      "[1390]\tvalid_0's l2: 0.164219\n",
      "[1391]\tvalid_0's l2: 0.164239\n",
      "[1392]\tvalid_0's l2: 0.164261\n",
      "[1393]\tvalid_0's l2: 0.164278\n",
      "[1394]\tvalid_0's l2: 0.164295\n",
      "[1395]\tvalid_0's l2: 0.164311\n",
      "[1396]\tvalid_0's l2: 0.164333\n",
      "[1397]\tvalid_0's l2: 0.164353\n",
      "[1398]\tvalid_0's l2: 0.164375\n",
      "[1399]\tvalid_0's l2: 0.164396\n",
      "[1400]\tvalid_0's l2: 0.164417\n",
      "[1401]\tvalid_0's l2: 0.164437\n",
      "[1402]\tvalid_0's l2: 0.164454\n",
      "[1403]\tvalid_0's l2: 0.16447\n",
      "[1404]\tvalid_0's l2: 0.164492\n",
      "[1405]\tvalid_0's l2: 0.164512\n",
      "[1406]\tvalid_0's l2: 0.164534\n",
      "[1407]\tvalid_0's l2: 0.164561\n",
      "[1408]\tvalid_0's l2: 0.164583\n",
      "[1409]\tvalid_0's l2: 0.164602\n",
      "[1410]\tvalid_0's l2: 0.16462\n",
      "[1411]\tvalid_0's l2: 0.164635\n",
      "[1412]\tvalid_0's l2: 0.164657\n",
      "[1413]\tvalid_0's l2: 0.164677\n",
      "[1414]\tvalid_0's l2: 0.164699\n",
      "[1415]\tvalid_0's l2: 0.16472\n",
      "[1416]\tvalid_0's l2: 0.164741\n",
      "[1417]\tvalid_0's l2: 0.164759\n",
      "[1418]\tvalid_0's l2: 0.164779\n",
      "[1419]\tvalid_0's l2: 0.164801\n",
      "[1420]\tvalid_0's l2: 0.164816\n",
      "[1421]\tvalid_0's l2: 0.164835\n",
      "[1422]\tvalid_0's l2: 0.164857\n",
      "[1423]\tvalid_0's l2: 0.164874\n",
      "[1424]\tvalid_0's l2: 0.164887\n",
      "[1425]\tvalid_0's l2: 0.164909\n",
      "[1426]\tvalid_0's l2: 0.164924\n",
      "[1427]\tvalid_0's l2: 0.164937\n",
      "[1428]\tvalid_0's l2: 0.164959\n",
      "[1429]\tvalid_0's l2: 0.164975\n",
      "[1430]\tvalid_0's l2: 0.164997\n",
      "[1431]\tvalid_0's l2: 0.165014\n",
      "[1432]\tvalid_0's l2: 0.165029\n",
      "[1433]\tvalid_0's l2: 0.165049\n",
      "[1434]\tvalid_0's l2: 0.165071\n",
      "[1435]\tvalid_0's l2: 0.165084\n",
      "[1436]\tvalid_0's l2: 0.165106\n",
      "[1437]\tvalid_0's l2: 0.165122\n",
      "[1438]\tvalid_0's l2: 0.165144\n",
      "[1439]\tvalid_0's l2: 0.16516\n",
      "[1440]\tvalid_0's l2: 0.165175\n",
      "[1441]\tvalid_0's l2: 0.165188\n",
      "[1442]\tvalid_0's l2: 0.16521\n",
      "[1443]\tvalid_0's l2: 0.165223\n",
      "[1444]\tvalid_0's l2: 0.165245\n",
      "[1445]\tvalid_0's l2: 0.165261\n",
      "[1446]\tvalid_0's l2: 0.165274\n",
      "[1447]\tvalid_0's l2: 0.165296\n",
      "[1448]\tvalid_0's l2: 0.165316\n",
      "[1449]\tvalid_0's l2: 0.165337\n",
      "[1450]\tvalid_0's l2: 0.165359\n",
      "[1451]\tvalid_0's l2: 0.165364\n",
      "[1452]\tvalid_0's l2: 0.16538\n",
      "[1453]\tvalid_0's l2: 0.165397\n",
      "[1454]\tvalid_0's l2: 0.165418\n",
      "[1455]\tvalid_0's l2: 0.16543\n",
      "[1456]\tvalid_0's l2: 0.165452\n",
      "[1457]\tvalid_0's l2: 0.165468\n",
      "[1458]\tvalid_0's l2: 0.16549\n",
      "[1459]\tvalid_0's l2: 0.165495\n",
      "[1460]\tvalid_0's l2: 0.165507\n",
      "[1461]\tvalid_0's l2: 0.165529\n",
      "[1462]\tvalid_0's l2: 0.165541\n",
      "[1463]\tvalid_0's l2: 0.165558\n",
      "[1464]\tvalid_0's l2: 0.165579\n",
      "[1465]\tvalid_0's l2: 0.165588\n",
      "[1466]\tvalid_0's l2: 0.165609\n",
      "[1467]\tvalid_0's l2: 0.165621\n",
      "[1468]\tvalid_0's l2: 0.165643\n",
      "[1469]\tvalid_0's l2: 0.165652\n",
      "[1470]\tvalid_0's l2: 0.165673\n",
      "[1471]\tvalid_0's l2: 0.165685\n",
      "[1472]\tvalid_0's l2: 0.165706\n",
      "[1473]\tvalid_0's l2: 0.165715\n",
      "[1474]\tvalid_0's l2: 0.165737\n",
      "[1475]\tvalid_0's l2: 0.165745\n",
      "[1476]\tvalid_0's l2: 0.165767\n",
      "[1477]\tvalid_0's l2: 0.165783\n",
      "[1478]\tvalid_0's l2: 0.1658\n",
      "[1479]\tvalid_0's l2: 0.165811\n",
      "[1480]\tvalid_0's l2: 0.165833\n",
      "[1481]\tvalid_0's l2: 0.165854\n",
      "[1482]\tvalid_0's l2: 0.165866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1483]\tvalid_0's l2: 0.165887\n",
      "[1484]\tvalid_0's l2: 0.165896\n",
      "[1485]\tvalid_0's l2: 0.165917\n",
      "[1486]\tvalid_0's l2: 0.165929\n",
      "[1487]\tvalid_0's l2: 0.165951\n",
      "[1488]\tvalid_0's l2: 0.165959\n",
      "[1489]\tvalid_0's l2: 0.165974\n",
      "[1490]\tvalid_0's l2: 0.165985\n",
      "[1491]\tvalid_0's l2: 0.165994\n",
      "[1492]\tvalid_0's l2: 0.166013\n",
      "[1493]\tvalid_0's l2: 0.166025\n",
      "[1494]\tvalid_0's l2: 0.166044\n",
      "[1495]\tvalid_0's l2: 0.166053\n",
      "[1496]\tvalid_0's l2: 0.166075\n",
      "[1497]\tvalid_0's l2: 0.166083\n",
      "[1498]\tvalid_0's l2: 0.166103\n",
      "[1499]\tvalid_0's l2: 0.166115\n",
      "[1500]\tvalid_0's l2: 0.166134\n",
      "[1501]\tvalid_0's l2: 0.166143\n",
      "[1502]\tvalid_0's l2: 0.166164\n",
      "[1503]\tvalid_0's l2: 0.166176\n",
      "[1504]\tvalid_0's l2: 0.166195\n",
      "[1505]\tvalid_0's l2: 0.166204\n",
      "[1506]\tvalid_0's l2: 0.166223\n",
      "[1507]\tvalid_0's l2: 0.166235\n",
      "[1508]\tvalid_0's l2: 0.166255\n",
      "[1509]\tvalid_0's l2: 0.166263\n",
      "[1510]\tvalid_0's l2: 0.16628\n",
      "[1511]\tvalid_0's l2: 0.166299\n",
      "[1512]\tvalid_0's l2: 0.166316\n",
      "[1513]\tvalid_0's l2: 0.166324\n",
      "[1514]\tvalid_0's l2: 0.166345\n",
      "[1515]\tvalid_0's l2: 0.166354\n",
      "[1516]\tvalid_0's l2: 0.166374\n",
      "[1517]\tvalid_0's l2: 0.16639\n",
      "[1518]\tvalid_0's l2: 0.166402\n",
      "[1519]\tvalid_0's l2: 0.166421\n",
      "[1520]\tvalid_0's l2: 0.16643\n",
      "[1521]\tvalid_0's l2: 0.166449\n",
      "[1522]\tvalid_0's l2: 0.166461\n",
      "[1523]\tvalid_0's l2: 0.166482\n",
      "[1524]\tvalid_0's l2: 0.16649\n",
      "[1525]\tvalid_0's l2: 0.166506\n",
      "[1526]\tvalid_0's l2: 0.166522\n",
      "[1527]\tvalid_0's l2: 0.166531\n",
      "[1528]\tvalid_0's l2: 0.166547\n",
      "[1529]\tvalid_0's l2: 0.166559\n",
      "[1530]\tvalid_0's l2: 0.166574\n",
      "[1531]\tvalid_0's l2: 0.166583\n",
      "[1532]\tvalid_0's l2: 0.166599\n",
      "[1533]\tvalid_0's l2: 0.166611\n",
      "[1534]\tvalid_0's l2: 0.166629\n",
      "[1535]\tvalid_0's l2: 0.166638\n",
      "[1536]\tvalid_0's l2: 0.166651\n",
      "[1537]\tvalid_0's l2: 0.166654\n",
      "[1538]\tvalid_0's l2: 0.166672\n",
      "[1539]\tvalid_0's l2: 0.16669\n",
      "Early stopping, best iteration is:\n",
      "[539]\tvalid_0's l2: 0.152982\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "cv_lgb_train = lgb.Dataset(cv_train_x,cv_train_y)\n",
    "cv_lgb_eval = lgb.Dataset(cv_eva_x,cv_eva_y,reference=cv_lgb_train)\n",
    " \n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 300,\n",
    "    'learning_rate': 0.003,\n",
    "#    'num_iterations':2000,\n",
    "#    'feature_fraction': 0.3,\n",
    "#    'bagging_fraction': 0.79,\n",
    "#    'bagging_freq': 7,\n",
    "#    'verbose': 0\n",
    "}\n",
    "\n",
    "cv_model_lgb = lgb.train(params,\n",
    "                cv_lgb_train,\n",
    "                num_boost_round=5000,\n",
    "                valid_sets=cv_lgb_eval,\n",
    "                early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.7882882882882883\n",
      "train: 0.8266068759342302\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(cv_model_lgb.predict(cv_eva_x, num_iteration=cv_model_lgb.best_iteration)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(cv_model_lgb.predict(cv_train_x, num_iteration=cv_model_lgb.best_iteration)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['LightGBM',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv_y_pred = np.round(cv_model_lgb.predict(cv_test_data, num_iteration=cv_model_lgb.best_iteration)).astype(int)\n",
    "cv_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out = pd.read_csv(\"test.csv\")\n",
    "df_out[\"Survived\"] = cv_y_pred\n",
    "\n",
    "# outputディレクトリに出力する\n",
    "df_out[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#モデルの定義\n",
    "#Sequential()の中に[]でレイヤーを並べるとモデルができる\n",
    "#Flatten：データを直列に並べる\n",
    "#Dense:全結合層。全セルからの入力を受ける\n",
    "#activation:活性化関数\n",
    "#Dropout(0.2):20%のデータを捨てて偏りをなくす\n",
    "#softmax:多クラスの分類時はsoftmax、1クラスの時はシグモイドを使うのが良い\n",
    "\n",
    "#model =keras.models.Sequential([\n",
    "#    keras.layers.Flatten(),\n",
    "#    keras.layers.Dense(512,activation='relu'),\n",
    "#    keras.layers.Dropout(0.2),\n",
    "#    keras.layers.Dense(10,activation='softmax')\n",
    "#                               ])\n",
    "\n",
    "cv_model_dl =keras.models.Sequential([\n",
    "    keras.layers.Dense(20,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(2,activation='softmax')\n",
    "                               ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#モデルと最適化手法の宣言を結びつける\n",
    "#最適化手法のメジャーなものとして、Adam,RMSprop,SGDなどがある\n",
    "#compileの構成は結果により調整すること\n",
    "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "cv_model_dl.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "669/669 [==============================] - 0s 250us/sample - loss: 0.6392 - acc: 0.6562\n",
      "Epoch 2/20\n",
      "669/669 [==============================] - 0s 40us/sample - loss: 0.5557 - acc: 0.7115\n",
      "Epoch 3/20\n",
      "669/669 [==============================] - 0s 43us/sample - loss: 0.5284 - acc: 0.7429\n",
      "Epoch 4/20\n",
      "669/669 [==============================] - 0s 37us/sample - loss: 0.5096 - acc: 0.7758\n",
      "Epoch 5/20\n",
      "669/669 [==============================] - 0s 42us/sample - loss: 0.5028 - acc: 0.7922\n",
      "Epoch 6/20\n",
      "669/669 [==============================] - 0s 36us/sample - loss: 0.5012 - acc: 0.7788\n",
      "Epoch 7/20\n",
      "669/669 [==============================] - 0s 37us/sample - loss: 0.4892 - acc: 0.7922\n",
      "Epoch 8/20\n",
      "669/669 [==============================] - 0s 40us/sample - loss: 0.4793 - acc: 0.7952\n",
      "Epoch 9/20\n",
      "669/669 [==============================] - 0s 39us/sample - loss: 0.4839 - acc: 0.7907\n",
      "Epoch 10/20\n",
      "669/669 [==============================] - 0s 36us/sample - loss: 0.4822 - acc: 0.7937\n",
      "Epoch 11/20\n",
      "669/669 [==============================] - 0s 42us/sample - loss: 0.4836 - acc: 0.7982\n",
      "Epoch 12/20\n",
      "669/669 [==============================] - 0s 37us/sample - loss: 0.4696 - acc: 0.8042\n",
      "Epoch 13/20\n",
      "669/669 [==============================] - 0s 42us/sample - loss: 0.4725 - acc: 0.8027\n",
      "Epoch 14/20\n",
      "669/669 [==============================] - 0s 39us/sample - loss: 0.4687 - acc: 0.8117\n",
      "Epoch 15/20\n",
      "669/669 [==============================] - 0s 39us/sample - loss: 0.4720 - acc: 0.7982\n",
      "Epoch 16/20\n",
      "669/669 [==============================] - 0s 36us/sample - loss: 0.4730 - acc: 0.7952\n",
      "Epoch 17/20\n",
      "669/669 [==============================] - 0s 36us/sample - loss: 0.4635 - acc: 0.7982\n",
      "Epoch 18/20\n",
      "669/669 [==============================] - 0s 37us/sample - loss: 0.4689 - acc: 0.7982\n",
      "Epoch 19/20\n",
      "669/669 [==============================] - 0s 37us/sample - loss: 0.4727 - acc: 0.8012\n",
      "Epoch 20/20\n",
      "669/669 [==============================] - 0s 36us/sample - loss: 0.4598 - acc: 0.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b70f0b2da0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#何度もloss,optimizer,epochsやそもそも説明変数自体を変えてよい結果になるまで行う\n",
    "cv_model_dl.fit(cv_train_x.values,cv_train_y_onehot.values,epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 225us/sample - loss: 0.4470 - acc: 0.8018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.447, 0.8018018]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習に未使用データで識別性能の確認を行う\n",
    "cv_model_dl.evaluate(cv_eva_x,cv_eva_y_onehot)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.8018018018018018\n",
      "train: 0.8101644245142003\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(cv_model_dl.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y_onehot,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(cv_model_dl.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y_onehot,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['NN',accuracy_score(cv_eva_y_onehot,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prediction = np.round(cv_model_dl.predict_proba(cv_test_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class = y_prediction[:,1]\n",
    "y_class.astype(np.int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テスト値を再読み込み\n",
    "df_out = pd.read_csv(\"test.csv\")\n",
    "df_out[\"Survived\"] = y_class.astype(np.int)\n",
    "\n",
    "# outputディレクトリに出力する\n",
    "df_out[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# いろんなモデルを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.480"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = logreg.predict(cv_test_data)\n",
    "acc_log = round(logreg.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.7927927927927928\n",
      "train: 0.7847533632286996\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(logreg.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(logreg.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['logreg',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.020"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = svc.predict(cv_test_data)\n",
    "acc_svc = round(svc.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.8018018018018018\n",
      "train: 0.8101644245142003\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(svc.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(svc.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['svc',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.600"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = knn.predict(cv_test_data)\n",
    "acc_knn = round(knn.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.7747747747747747\n",
      "train: 0.8460388639760837\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(knn.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(knn.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['knn',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.620"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = gaussian.predict(cv_test_data)\n",
    "acc_gaussian = round(gaussian.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_gaussian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.8063063063063063\n",
      "train: 0.7862481315396114\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(gaussian.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(gaussian.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['Gaussian ',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.330"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = perceptron.predict(cv_test_data)\n",
    "acc_perceptron = round(perceptron.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.8063063063063063\n",
      "train: 0.7832585949177877\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(perceptron.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(perceptron.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['perceptron',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.180"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = linear_svc.predict(cv_test_data)\n",
    "acc_linear_svc = round(linear_svc.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.7927927927927928\n",
      "train: 0.7817638266068759\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(linear_svc.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(linear_svc.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['linear_svc',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.730"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = sgd.predict(cv_test_data)\n",
    "acc_sgd = round(sgd.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.7657657657657657\n",
      "train: 0.7772795216741405\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(sgd.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(sgd.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['sgd',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.530"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = decision_tree.predict(cv_test_data)\n",
    "acc_decision_tree = round(decision_tree.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_decision_tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.7657657657657657\n",
      "train: 0.9252615844544095\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(decision_tree.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(decision_tree.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['decision_tree',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.550"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "#random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=15,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "random_forest.fit(cv_train_x, cv_train_y)\n",
    "Y_pred = random_forest.predict(cv_test_data)\n",
    "random_forest.score(cv_train_x, cv_train_y)\n",
    "acc_random_forest = round(random_forest.score(cv_train_x, cv_train_y) * 100, 2)\n",
    "acc_random_forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.8018018018018018\n",
      "train: 0.8654708520179372\n"
     ]
    }
   ],
   "source": [
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(random_forest.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(random_forest.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['random_forest',accuracy_score(cv_eva_y,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.788288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.801802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.792793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.801802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.774775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.806306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perceptron</td>\n",
       "      <td>0.806306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>0.792793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sgd</td>\n",
       "      <td>0.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.801802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model     score\n",
       "0       LightGBM  0.788288\n",
       "0             NN  0.801802\n",
       "0         logreg  0.792793\n",
       "0            svc  0.801802\n",
       "0            knn  0.774775\n",
       "0      Gaussian   0.806306\n",
       "0     perceptron  0.806306\n",
       "0     linear_svc  0.792793\n",
       "0            sgd  0.765766\n",
       "0  decision_tree  0.765766\n",
       "0  random_forest  0.801802"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#モデル事の精度をチェック\n",
    "#最も良いものを次で出力すること\n",
    "model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva: 0.8063063063063063\n",
      "train: 0.8131539611360239\n"
     ]
    }
   ],
   "source": [
    "#アンサンブル\n",
    "eclf = VotingClassifier(estimators=[ ('perceptron',perceptron),('random_forest', random_forest),('gaussian',gaussian)], voting='hard')\n",
    "#eclf = VotingClassifier(estimators=[('LightGBM', cv_model_lgb), ('NN', cv_model_dl), ('random_forest', random_forest)], voting='hard')\n",
    "\n",
    "\n",
    "eclf.fit(cv_train_x, cv_train_y)\n",
    "cv_Y_pred = np.round(eclf.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(eclf.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y,cv_Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#出力箇所_モデル名は変えること\n",
    "y_prediction = np.round(random_forest.predict_proba(cv_test_data))\n",
    "y_class = y_prediction[:,1]\n",
    "y_class.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out = pd.read_csv(\"test.csv\")\n",
    "df_out[\"Survived\"] = cv_y_pred\n",
    "\n",
    "# outputディレクトリに出力する\n",
    "df_out[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ここからグリッドサーチの練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid search\n",
    "gs_model_dl =keras.models.Sequential()\n",
    "model = KerasClassifier(build_fn=gs_model_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#out_dim=np.logspace(10,200,num=20)\n",
    "#out_dim=[10,20,30,40,50]\n",
    "out_dim=20\n",
    "out_dim2=20\n",
    "activation = [\"relu\", \"sigmoid\"],\n",
    "optimizer = [\"adam\", \"adagrad\"]\n",
    "nb_epoch = [10, 25]\n",
    "batch_size = [5, 10]\n",
    "drop_out=np.logspace(0.1,0.5,num=10)\n",
    "init = ['glorot_uniform', 'normal', 'uniform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gs_model_dl.add(keras.layers.Dense(20,activation='relu'))\n",
    "gs_model_dl.add(keras.layers.Dropout(0.1))\n",
    "gs_model_dl.add(keras.layers.Dense(100,activation='relu'))\n",
    "gs_model_dl.add(keras.layers.Dropout(0.1))\n",
    "gs_model_dl.add(keras.layers.Dense(2,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-c55fdc614154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                   init=init)\n\u001b[0;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_train_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             raise TypeError(\"Cannot clone object '%s' (type %s): \"\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# If is its own copy, don't memoize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# If is its own copy, don't memoize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-cpu\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce_ex__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreductor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                         \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "\n",
    "# KerasClassifier/KerasRegressor can be used as same as scikit_learn estimator.\n",
    "model = KerasClassifier(build_fn=gs_model_dl)\n",
    "\n",
    "# Grid Search parameters (epochs, batch size and optimizer)\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [10, 20, 30]\n",
    "batches = [5, 10, 20]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches,\n",
    "                  init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(cv_train_x.values,cv_train_y)\n",
    "\n",
    "# summarize results\n",
    "print(grid_result.best_params_)\n",
    "#print(\"Best parameter set: {}\".format(grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = dict(optimizer=optimizer, epochs=nb_epoch, batch_size=batch_size,\n",
    "                  init=init)\n",
    "grid = GridSearchCV(estimator=gs_model_dl, param_grid=param_grid)\n",
    "\n",
    "grid.fit(cv_train_x.values,cv_train_y_onehot.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?gs_model_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_model_dl.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "gs_model_dl.fit(cv_train_x.values,cv_train_y_onehot.values,epochs=20)\n",
    "gs_model_dl.evaluate(cv_eva_x,cv_eva_y_onehot)\n",
    "\n",
    "#精度計算+過学習チェック\n",
    "cv_Y_pred = np.round(gs_model_dl.predict(cv_eva_x)).astype(int)\n",
    "print('eva:',accuracy_score(cv_eva_y_onehot,cv_Y_pred))\n",
    "cv_Y_pred_train=np.round(gs_model_dl.predict(cv_train_x)).astype(int)\n",
    "print('train:',accuracy_score(cv_train_y_onehot,cv_Y_pred_train))\n",
    "\n",
    "model_score=model_score.append(pd.DataFrame(['NN',accuracy_score(cv_eva_y_onehot,cv_Y_pred)],index=['model', 'score']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
