{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: 指定されたモジュールが見つかりません。\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: 指定されたモジュールが見つかりません。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-932c10840511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: 指定されたモジュールが見つかりません。\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "import gc\n",
    "from catboost import CatBoostRegressor\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#import os\n",
    "#print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get data\n",
    "X_reader = pd.read_csv(\"lanl-features/train_features.csv\", nrows=10000000,\n",
    "                    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hann_window_mean_150</th>\n",
       "      <th>Hann_window_mean_1500</th>\n",
       "      <th>Hann_window_mean_15000</th>\n",
       "      <th>Hann_window_mean_50</th>\n",
       "      <th>Hilbert_mean</th>\n",
       "      <th>abs_energy</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>abs_max_roll_mean_10</th>\n",
       "      <th>abs_max_roll_mean_100</th>\n",
       "      <th>abs_max_roll_mean_1000</th>\n",
       "      <th>...</th>\n",
       "      <th>time_rev_asym_stat_1</th>\n",
       "      <th>time_rev_asym_stat_10</th>\n",
       "      <th>time_rev_asym_stat_100</th>\n",
       "      <th>time_rev_asym_stat_1000</th>\n",
       "      <th>time_rev_asym_stat_10000</th>\n",
       "      <th>time_rev_asym_stat_5</th>\n",
       "      <th>time_rev_asym_stat_50</th>\n",
       "      <th>time_rev_asym_stat_500</th>\n",
       "      <th>trend</th>\n",
       "      <th>var_larger_than_std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.883327023570954</td>\n",
       "      <td>4.876660693097298</td>\n",
       "      <td>4.809075953159121</td>\n",
       "      <td>4.883859523420638</td>\n",
       "      <td>7.027028035412704</td>\n",
       "      <td>7481351.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>68.500000000000000</td>\n",
       "      <td>10.039999999999999</td>\n",
       "      <td>5.629000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177655702076028</td>\n",
       "      <td>-14.764688625150020</td>\n",
       "      <td>-1.703217623497997</td>\n",
       "      <td>1.169500000000000</td>\n",
       "      <td>-51.047107692307691</td>\n",
       "      <td>-0.958330555370358</td>\n",
       "      <td>5.087825216811208</td>\n",
       "      <td>5.671832214765103</td>\n",
       "      <td>-0.000003268299817</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.725049132238183</td>\n",
       "      <td>4.718420573548181</td>\n",
       "      <td>4.653152157320807</td>\n",
       "      <td>4.725527100974546</td>\n",
       "      <td>7.380382529587168</td>\n",
       "      <td>9861777.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>145.099999999999994</td>\n",
       "      <td>16.670000000000002</td>\n",
       "      <td>5.667000000000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284957132761770</td>\n",
       "      <td>91.001093479130560</td>\n",
       "      <td>-38.729232309746330</td>\n",
       "      <td>-0.665972972972973</td>\n",
       "      <td>-52.383715384615385</td>\n",
       "      <td>71.814107607173810</td>\n",
       "      <td>21.336684456304198</td>\n",
       "      <td>23.323973154362417</td>\n",
       "      <td>0.000000909042448</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.905511258078014</td>\n",
       "      <td>4.898920772317807</td>\n",
       "      <td>4.832203777557303</td>\n",
       "      <td>4.906040032534657</td>\n",
       "      <td>8.016930170432310</td>\n",
       "      <td>10892549.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.799999999999997</td>\n",
       "      <td>12.380000000000001</td>\n",
       "      <td>5.957000000000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693162575501007</td>\n",
       "      <td>-105.719162555007301</td>\n",
       "      <td>78.751722296395187</td>\n",
       "      <td>4.284682432432431</td>\n",
       "      <td>46.923230769230784</td>\n",
       "      <td>-57.852130142009457</td>\n",
       "      <td>41.037611741160774</td>\n",
       "      <td>46.940375838926172</td>\n",
       "      <td>0.000003962181680</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.901427864908424</td>\n",
       "      <td>4.894639042521090</td>\n",
       "      <td>4.827671244276916</td>\n",
       "      <td>4.901984819425586</td>\n",
       "      <td>7.606849953983147</td>\n",
       "      <td>10792492.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>136.599999999999994</td>\n",
       "      <td>18.260000000000002</td>\n",
       "      <td>5.858000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234849797997307</td>\n",
       "      <td>11.626423523136420</td>\n",
       "      <td>263.667817089452569</td>\n",
       "      <td>20.922364864864864</td>\n",
       "      <td>-13.254976923076926</td>\n",
       "      <td>22.071564770984725</td>\n",
       "      <td>-85.625096731154102</td>\n",
       "      <td>4.832550335570470</td>\n",
       "      <td>0.000001637207225</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.908115126624049</td>\n",
       "      <td>4.901854958025392</td>\n",
       "      <td>4.836297018529053</td>\n",
       "      <td>4.908528375436501</td>\n",
       "      <td>7.895402664474322</td>\n",
       "      <td>11610208.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>107.599999999999994</td>\n",
       "      <td>14.410000000000000</td>\n",
       "      <td>6.077999999999999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126008346777957</td>\n",
       "      <td>12.574096546206160</td>\n",
       "      <td>99.323571428571441</td>\n",
       "      <td>-14.195959459459459</td>\n",
       "      <td>17.525423076923076</td>\n",
       "      <td>18.980185345689712</td>\n",
       "      <td>59.390660440293530</td>\n",
       "      <td>-17.780355704697982</td>\n",
       "      <td>-0.000000666839221</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hann_window_mean_150  Hann_window_mean_1500  Hann_window_mean_15000  \\\n",
       "0     4.883327023570954      4.876660693097298       4.809075953159121   \n",
       "1     4.725049132238183      4.718420573548181       4.653152157320807   \n",
       "2     4.905511258078014      4.898920772317807       4.832203777557303   \n",
       "3     4.901427864908424      4.894639042521090       4.827671244276916   \n",
       "4     4.908115126624049      4.901854958025392       4.836297018529053   \n",
       "\n",
       "   Hann_window_mean_50       Hilbert_mean  abs_energy  abs_max  \\\n",
       "0    4.883859523420638  7.027028035412704   7481351.0    104.0   \n",
       "1    4.725527100974546  7.380382529587168   9861777.0    181.0   \n",
       "2    4.906040032534657  8.016930170432310  10892549.0    140.0   \n",
       "3    4.901984819425586  7.606849953983147  10792492.0    199.0   \n",
       "4    4.908528375436501  7.895402664474322  11610208.0    145.0   \n",
       "\n",
       "   abs_max_roll_mean_10  abs_max_roll_mean_100  abs_max_roll_mean_1000  ...  \\\n",
       "0    68.500000000000000     10.039999999999999       5.629000000000000  ...   \n",
       "1   145.099999999999994     16.670000000000002       5.667000000000002  ...   \n",
       "2    94.799999999999997     12.380000000000001       5.957000000000002  ...   \n",
       "3   136.599999999999994     18.260000000000002       5.858000000000000  ...   \n",
       "4   107.599999999999994     14.410000000000000       6.077999999999999  ...   \n",
       "\n",
       "   time_rev_asym_stat_1  time_rev_asym_stat_10  time_rev_asym_stat_100  \\\n",
       "0    -0.177655702076028    -14.764688625150020      -1.703217623497997   \n",
       "1    -0.284957132761770     91.001093479130560     -38.729232309746330   \n",
       "2    -0.693162575501007   -105.719162555007301      78.751722296395187   \n",
       "3     0.234849797997307     11.626423523136420     263.667817089452569   \n",
       "4     0.126008346777957     12.574096546206160      99.323571428571441   \n",
       "\n",
       "   time_rev_asym_stat_1000  time_rev_asym_stat_10000  time_rev_asym_stat_5  \\\n",
       "0        1.169500000000000       -51.047107692307691    -0.958330555370358   \n",
       "1       -0.665972972972973       -52.383715384615385    71.814107607173810   \n",
       "2        4.284682432432431        46.923230769230784   -57.852130142009457   \n",
       "3       20.922364864864864       -13.254976923076926    22.071564770984725   \n",
       "4      -14.195959459459459        17.525423076923076    18.980185345689712   \n",
       "\n",
       "   time_rev_asym_stat_50  time_rev_asym_stat_500              trend  \\\n",
       "0      5.087825216811208       5.671832214765103 -0.000003268299817   \n",
       "1     21.336684456304198      23.323973154362417  0.000000909042448   \n",
       "2     41.037611741160774      46.940375838926172  0.000003962181680   \n",
       "3    -85.625096731154102       4.832550335570470  0.000001637207225   \n",
       "4     59.390660440293530     -17.780355704697982 -0.000000666839221   \n",
       "\n",
       "   var_larger_than_std_dev  \n",
       "0                     True  \n",
       "1                     True  \n",
       "2                     True  \n",
       "3                     True  \n",
       "4                     True  \n",
       "\n",
       "[5 rows x 981 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = pd.read_csv(\"lanl-features/y.csv\", nrows=10000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get data\n",
    "X_test = pd.read_csv(\"lanl-features/test_features.csv\", \n",
    "                    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#特徴量の正規化\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_reader)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_reader), columns=X_reader.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Shuta\\AppData\\Local\\conda\\conda\\envs\\tf111-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#特徴量の正規化\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからLightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(n_estimators=10000,learning_rate=0.0005, n_jobs=-1)\n",
    "model.fit(X_train_scaled,y_tr)\n",
    "y_pred_lgb = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XBboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = xgb.XGBRegressor(n_estimators=10)\n",
    "model.fit(X_train_scaled,y_tr)\n",
    "y_pred_xgb = model.predict(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-236c768059df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inputs = Input(shape=(24,))\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1)(x)\n",
    "model_3 = Model(inputs=inputs, outputs=predictions)\n",
    "model_3.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "                      loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "model_3.fit(X_train_scaled, y_tr, epochs=15, verbose=0)\n",
    "y_pred_nn = model.predict(X_test_scaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y_pred_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample['time_to_failure'] = (y_pred_lgb+y_pred_xgb+y_pred_nn)/3\n",
    "sample.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross varidation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "n_estimators = [10,100]\n",
    "\n",
    "for n_est in  n_estimators:\n",
    "    print(n_est)\n",
    "    cv = KFold(n_splits=5, shuffle=True,random_state=0)\n",
    "    for train, valid in cv.split(X_train_scaled, y_tr):\n",
    "        x_train = X_train_scaled.iloc[train]\n",
    "        x_valid = X_train_scaled.iloc[valid]\n",
    "        y_train = y_tr.iloc[train]\n",
    "        y_valid = y_tr.iloc[valid]\n",
    "        \n",
    "        model_1 = lgb.LGBMRegressor(n_estimators=10000, learning_rate=0.0005,n_jobs=-1,random_state=0)\n",
    "        model_1.fit(x_train, y_train)\n",
    "        y_pred_lgb = model_1.predict(x_valid)\n",
    "        \n",
    "        model_2 = xgb.XGBRegressor(n_estimators=n_est, n_jobs=-1,random_state=0)\n",
    "        model_2.fit(x_train, y_train)\n",
    "        y_pred_xgb = model_2.predict(x_valid)\n",
    "        \n",
    "        inputs = Input(shape=(24,))\n",
    "        x = Dense(128, activation='relu')(inputs)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        predictions = Dense(1)(x)\n",
    "        model_3 = Model(inputs=inputs, outputs=predictions)\n",
    "        model_3.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "                      loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "        model_3.fit(x_train, y_train, epochs=15, verbose=0)\n",
    "        y_pred_nn = model_3.predict(x_valid).flatten()\n",
    "        \n",
    "        y_pred = (y_pred_lgb+y_pred_xgb+y_pred_nn)/3\n",
    "        print(mean_absolute_error(y_valid, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ゴミ？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#訓練データの作成\n",
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\n",
    "X_test = pd.DataFrame(columns=X_tr.columns, dtype=np.float64, index=submission.index)\n",
    "plt.figure(figsize=(22, 16))\n",
    "\n",
    "for i, seg_id in enumerate(tqdm_notebook(X_test.index)):\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    \n",
    "    x = seg['acoustic_data'].values\n",
    "    X_test.loc[seg_id, 'ave'] = x.mean()\n",
    "    X_test.loc[seg_id, 'std'] = x.std()\n",
    "    X_test.loc[seg_id, 'max'] = x.max()\n",
    "    X_test.loc[seg_id, 'min'] = x.min()\n",
    "        \n",
    "    X_test.loc[seg_id, 'av_change_abs'] = np.mean(np.diff(x))\n",
    "    X_test.loc[seg_id, 'av_change_rate'] = np.mean(np.nonzero((np.diff(x) / x[:-1]))[0])\n",
    "    X_test.loc[seg_id, 'abs_max'] = np.abs(x).max()\n",
    "    X_test.loc[seg_id, 'abs_min'] = np.abs(x).min()\n",
    "    \n",
    "    X_test.loc[seg_id, 'std_first_50000'] = x[:50000].std()\n",
    "    X_test.loc[seg_id, 'std_last_50000'] = x[-50000:].std()\n",
    "    X_test.loc[seg_id, 'std_first_10000'] = x[:10000].std()\n",
    "    X_test.loc[seg_id, 'std_last_10000'] = x[-10000:].std()\n",
    "    \n",
    "    X_test.loc[seg_id, 'avg_first_50000'] = x[:50000].mean()\n",
    "    X_test.loc[seg_id, 'avg_last_50000'] = x[-50000:].mean()\n",
    "    X_test.loc[seg_id, 'avg_first_10000'] = x[:10000].mean()\n",
    "    X_test.loc[seg_id, 'avg_last_10000'] = x[-10000:].mean()\n",
    "    \n",
    "    X_test.loc[seg_id, 'min_first_50000'] = x[:50000].min()\n",
    "    X_test.loc[seg_id, 'min_last_50000'] = x[-50000:].min()\n",
    "    X_test.loc[seg_id, 'min_first_10000'] = x[:10000].min()\n",
    "    X_test.loc[seg_id, 'min_last_10000'] = x[-10000:].min()\n",
    "    \n",
    "    X_test.loc[seg_id, 'max_first_50000'] = x[:50000].max()\n",
    "    X_test.loc[seg_id, 'max_last_50000'] = x[-50000:].max()\n",
    "    X_test.loc[seg_id, 'max_first_10000'] = x[:10000].max()\n",
    "    X_test.loc[seg_id, 'max_last_10000'] = x[-10000:].max()\n",
    "    \n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#特徴量の作成\n",
    "%time\n",
    "\n",
    "rows = 150_000\n",
    "train = X\n",
    "segments = int(np.floor(train.shape[0] / rows))\n",
    "\n",
    "X_tr = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['ave', 'std', 'max', 'min',\n",
    "                               'av_change_abs', 'av_change_rate', 'abs_max', 'abs_min',\n",
    "                               'std_first_50000', 'std_last_50000', 'std_first_10000', 'std_last_10000',\n",
    "                               'avg_first_50000', 'avg_last_50000', 'avg_first_10000', 'avg_last_10000',\n",
    "                               'min_first_50000', 'min_last_50000', 'min_first_10000', 'min_last_10000',\n",
    "                               'max_first_50000', 'max_last_50000', 'max_first_10000', 'max_last_10000'])\n",
    "y_tr = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['time_to_failure'])\n",
    "\n",
    "total_mean = train['acoustic_data'].mean()\n",
    "total_std = train['acoustic_data'].std()\n",
    "total_max = train['acoustic_data'].max()\n",
    "total_min = train['acoustic_data'].min()\n",
    "total_sum = train['acoustic_data'].sum()\n",
    "total_abs_max = np.abs(train['acoustic_data']).sum()\n",
    "\n",
    "for segment in tqdm_notebook(range(segments)):\n",
    "    seg = train.iloc[segment*rows:segment*rows+rows]\n",
    "    x = seg['acoustic_data'].values\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    \n",
    "    y_tr.loc[segment, 'time_to_failure'] = y\n",
    "    X_tr.loc[segment, 'ave'] = x.mean()\n",
    "    X_tr.loc[segment, 'std'] = x.std()\n",
    "    X_tr.loc[segment, 'max'] = x.max()\n",
    "    X_tr.loc[segment, 'min'] = x.min()\n",
    "    \n",
    "    \n",
    "    X_tr.loc[segment, 'av_change_abs'] = np.mean(np.diff(x))\n",
    "    X_tr.loc[segment, 'av_change_rate'] = np.mean(np.nonzero((np.diff(x) / x[:-1]))[0])\n",
    "    X_tr.loc[segment, 'abs_max'] = np.abs(x).max()\n",
    "    X_tr.loc[segment, 'abs_min'] = np.abs(x).min()\n",
    "    \n",
    "    X_tr.loc[segment, 'std_first_50000'] = x[:50000].std()\n",
    "    X_tr.loc[segment, 'std_last_50000'] = x[-50000:].std()\n",
    "    X_tr.loc[segment, 'std_first_10000'] = x[:10000].std()\n",
    "    X_tr.loc[segment, 'std_last_10000'] = x[-10000:].std()\n",
    "    \n",
    "    X_tr.loc[segment, 'avg_first_50000'] = x[:50000].mean()\n",
    "    X_tr.loc[segment, 'avg_last_50000'] = x[-50000:].mean()\n",
    "    X_tr.loc[segment, 'avg_first_10000'] = x[:10000].mean()\n",
    "    X_tr.loc[segment, 'avg_last_10000'] = x[-10000:].mean()\n",
    "    \n",
    "    X_tr.loc[segment, 'min_first_50000'] = x[:50000].min()\n",
    "    X_tr.loc[segment, 'min_last_50000'] = x[-50000:].min()\n",
    "    X_tr.loc[segment, 'min_first_10000'] = x[:10000].min()\n",
    "    X_tr.loc[segment, 'min_last_10000'] = x[-10000:].min()\n",
    "    \n",
    "    X_tr.loc[segment, 'max_first_50000'] = x[:50000].max()\n",
    "    X_tr.loc[segment, 'max_last_50000'] = x[-50000:].max()\n",
    "    X_tr.loc[segment, 'max_first_10000'] = x[:10000].max()\n",
    "    X_tr.loc[segment, 'max_last_10000'] = x[-10000:].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
